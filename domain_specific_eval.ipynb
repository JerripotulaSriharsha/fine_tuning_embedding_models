{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60ee7a46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Narwal\\fine_tuning_embedding_models\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from sentence_transformers import SentenceTransformer, SentenceTransformerModelCardData, SentenceTransformerTrainingArguments, SentenceTransformerTrainer\n",
    "from sentence_transformers.evaluation import InformationRetrievalEvaluator, SequentialEvaluator\n",
    "from sentence_transformers.util import cos_sim\n",
    "from sentence_transformers.losses import MatryoshkaLoss, MultipleNegativesRankingLoss\n",
    "from sentence_transformers.training_args import BatchSamplers\n",
    "\n",
    "from datasets import load_dataset, concatenate_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f434b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"AdamLucek/legal-rag-positives-synthetic\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "353e5a31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 'Sh Synergy, LLC. v. United States', '2023-04-28',\n",
       "        'United States Court of Federal Claims',\n",
       "        '1 \\n \\nIn the United States Court of Federal Claims \\nSH SYNERGY, LLC and \\nVCH PARTNERS, LLC, \\n                         \\nPlaintiffs, \\n \\n \\n                                    v. \\n \\n \\nTHE UNITED STATES, \\n \\nDefendant, \\nNos. 22-cv-1466, 22-cv-1468 \\n(consolidated) \\n \\nFiled Under Seal: April 21, 2023 \\n \\nPublication: April 28, 20231',\n",
       "        2, 'When was the case released for publication?',\n",
       "        'Publication: April 28, 2023']], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "df = pd.DataFrame(dataset)\n",
    "df.iloc[[1],:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6153fc02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['chunk_id', 'global_chunk_id', 'case_name', 'date_filed', 'court',\n",
       "       'text', 'question_id', 'question', 'answer_location'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd1fd559",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.rename_column(\"question\", \"anchor\")\n",
    "dataset = dataset.rename_column(\"text\", \"positive\")\n",
    "dataset = dataset.remove_columns([\"chunk_id\", \"case_name\", \"date_filed\", \"court\", \"question_id\", \"answer_location\"]) # keep global_chunk_id\n",
    "\n",
    "# Add an id column to the dataset\n",
    "dataset = dataset.add_column(\"id\", range(len(dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8c5ab0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0,\n",
       "        '1 \\n \\nIn the United States Court of Federal Claims \\nSH SYNERGY, LLC and \\nVCH PARTNERS, LLC, \\n                         \\nPlaintiffs, \\n \\n \\n                                    v. \\n \\n \\nTHE UNITED STATES, \\n \\nDefendant, \\nNos. 22-cv-1466, 22-cv-1468 \\n(consolidated) \\n \\nFiled Under Seal: April 21, 2023 \\n \\nPublication: April 28, 20231',\n",
       "        'What are the case numbers associated with this legal matter?',\n",
       "        2]], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(dataset)\n",
    "df.iloc[[2],:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57ec5ae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating json from Arrow format: 100%|██████████| 6/6 [00:00<00:00, 197.12ba/s]\n",
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<?, ?ba/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "338495"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shuffle Dataset\n",
    "dataset = dataset.shuffle()\n",
    "\n",
    "# Split Dataset Into a 90/10 Train/Test split\n",
    "dataset = dataset.train_test_split(test_size=0.1)\n",
    "\n",
    "# Save Datasets to Disk\n",
    "dataset[\"train\"].to_json(\"train_dataset.json\", orient=\"records\")\n",
    "dataset[\"test\"].to_json(\"test_dataset.json\", orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06b0558a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hugging Face model ID\n",
    "model_id = \"nomic-ai/modernbert-embed-base\"\n",
    "\n",
    "# Loading via SentenceTransformer\n",
    "model = SentenceTransformer(\n",
    "    model_id, device=\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b0dcff05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 647 examples [00:00, 40431.39 examples/s]\n",
      "Generating train split: 5822 examples [00:00, 493477.44 examples/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load train and test datasets from their respective JSON files\n",
    "# These contain pairs of questions (anchors) and text chunks (positives)\n",
    "test_dataset = load_dataset(\"json\", data_files=\"test_dataset.json\", split=\"train\")\n",
    "train_dataset = load_dataset(\"json\", data_files=\"train_dataset.json\", split=\"train\")\n",
    "corpus_dataset = concatenate_datasets([train_dataset, test_dataset])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3018929b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1985 from her; that other classmates (but not plaintiff) publicly exposed the allegations against \n",
      "defendant on social media; that, in July 2022, defendant filed a defamation lawsuit against \n",
      "several classmates (but not plaintiff); and that, since filing suit, defendant threatened to add \n",
      "plaintiff to his defamation suit.2 In support of the last allegation, plaintiff attached a letter from\n",
      "-----    \n",
      "2782 What is the sequence position of the discussion about the plaintiff's claims on the CIA's refusal to process certain FOIA requests?\n"
     ]
    }
   ],
   "source": [
    "corpus = dict(\n",
    "    zip(corpus_dataset[\"id\"], corpus_dataset[\"positive\"])\n",
    ")\n",
    "queries = dict(\n",
    "    zip(test_dataset[\"id\"], test_dataset[\"anchor\"])\n",
    ")\n",
    "\n",
    "for i,j in corpus.items():\n",
    "    print(i, j)\n",
    "    break\n",
    "print(\"-----    \")\n",
    "\n",
    "for i,j in queries.items():\n",
    "    print(i, j)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f9e4fba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_docs = {}\n",
    "\n",
    "for id_test, chunk_id_test in zip(test_dataset[\"id\"], test_dataset[\"global_chunk_id\"]):\n",
    "    relevant_docs[id_test] = []\n",
    "\n",
    "    for id_corpus, chunk_id_corpus in zip(\n",
    "        corpus_dataset[\"id\"], corpus_dataset[\"global_chunk_id\"]\n",
    "    ):\n",
    "        if chunk_id_test == chunk_id_corpus:\n",
    "            relevant_docs[id_test].append(id_corpus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a403668",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2782: [2783, 2781, 2782],\n",
       " 2531: [2532, 2531],\n",
       " 5359: [5358, 5356, 5359, 5357],\n",
       " 1817: [1814, 1815, 1816, 1817],\n",
       " 2273: [2272, 2274, 2275, 2273],\n",
       " 6109: [6108, 6109, 6107],\n",
       " 2812: [2810, 2811, 2812],\n",
       " 6191: [6190, 6191],\n",
       " 3762: [3763, 3761, 3762],\n",
       " 859: [858, 857, 859],\n",
       " 716: [715, 714, 716],\n",
       " 1866: [1869, 1868, 1867, 1866],\n",
       " 5103: [5103],\n",
       " 5223: [5222, 5223],\n",
       " 5306: [5308, 5305, 5307, 5306],\n",
       " 3249: [3248, 3247, 3249],\n",
       " 602: [599, 601, 600, 602],\n",
       " 6107: [6108, 6109, 6107],\n",
       " 3776: [3775, 3776],\n",
       " 4052: [4050, 4051, 4052],\n",
       " 2519: [2517, 2516, 2518, 2519],\n",
       " 3658: [3657, 3656, 3659, 3658],\n",
       " 766: [765, 767, 764, 766],\n",
       " 3312: [3310, 3311, 3312],\n",
       " 221: [219, 220, 222, 221],\n",
       " 1297: [1298, 1299, 1297],\n",
       " 1358: [1360, 1358, 1359],\n",
       " 1467: [1469, 1470, 1468, 1467],\n",
       " 1927: [1928, 1927],\n",
       " 4711: [4712, 4713, 4714, 4711],\n",
       " 5357: [5358, 5356, 5359, 5357],\n",
       " 3682: [3681, 3682],\n",
       " 2614: [2612, 2613, 2615, 2614],\n",
       " 5192: [5192],\n",
       " 77: [78, 77],\n",
       " 288: [290, 291, 289, 288],\n",
       " 4567: [4564, 4565, 4566, 4567],\n",
       " 719: [720, 719],\n",
       " 6174: [6175, 6174],\n",
       " 195: [194, 192, 193, 195],\n",
       " 6348: [6347, 6348],\n",
       " 1466: [1465, 1464, 1466],\n",
       " 943: [942, 944, 943],\n",
       " 3211: [3212, 3211],\n",
       " 1430: [1431, 1432, 1433, 1430],\n",
       " 6138: [6137, 6139, 6136, 6138],\n",
       " 4463: [4464, 4463],\n",
       " 4252: [4251, 4252, 4250],\n",
       " 3194: [3195, 3194],\n",
       " 5597: [5595, 5598, 5597, 5596],\n",
       " 2238: [2237, 2235, 2236, 2238],\n",
       " 1984: [1985, 1983, 1984, 1986],\n",
       " 6410: [6412, 6410, 6411],\n",
       " 1249: [1251, 1250, 1252, 1249],\n",
       " 211: [210, 212, 211],\n",
       " 4105: [4102, 4104, 4103, 4105],\n",
       " 1288: [1289, 1290, 1288],\n",
       " 4539: [4538, 4539, 4537],\n",
       " 681: [683, 680, 682, 681],\n",
       " 5134: [5132, 5131, 5133, 5134],\n",
       " 5657: [5655, 5656, 5657],\n",
       " 2334: [2333, 2335, 2334],\n",
       " 4324: [4323, 4322, 4324],\n",
       " 3493: [3494, 3492, 3493],\n",
       " 1852: [1851, 1853, 1854, 1852],\n",
       " 1322: [1321, 1323, 1322],\n",
       " 5932: [5930, 5931, 5933, 5932],\n",
       " 1812: [1811, 1813, 1812],\n",
       " 433: [436, 435, 434, 433],\n",
       " 4297: [4298, 4297],\n",
       " 1629: [1631, 1630, 1629],\n",
       " 1245: [1246, 1247, 1245],\n",
       " 5389: [5388, 5387, 5390, 5389],\n",
       " 95: [94, 96, 95],\n",
       " 700: [701, 702, 699, 700],\n",
       " 1872: [1874, 1873, 1872, 1875],\n",
       " 5236: [5239, 5238, 5236, 5237],\n",
       " 1530: [1529, 1530],\n",
       " 3404: [3405, 3404, 3403],\n",
       " 1359: [1360, 1358, 1359],\n",
       " 4969: [4967, 4968, 4966, 4969],\n",
       " 2053: [2052, 2051, 2053],\n",
       " 807: [808, 807],\n",
       " 4195: [4197, 4196, 4198, 4195],\n",
       " 575: [575],\n",
       " 1422: [1421, 1420, 1422],\n",
       " 1956: [1953, 1955, 1954, 1956],\n",
       " 3814: [3813, 3814, 3812],\n",
       " 753: [751, 752, 750, 753],\n",
       " 449: [450, 451, 449],\n",
       " 2879: [2876, 2878, 2877, 2879],\n",
       " 4420: [4419, 4418, 4417, 4420],\n",
       " 679: [677, 678, 679],\n",
       " 3754: [3753, 3756, 3755, 3754],\n",
       " 4325: [4326, 4327, 4325],\n",
       " 3819: [3820, 3822, 3821, 3819],\n",
       " 5733: [5736, 5735, 5734, 5733],\n",
       " 116: [114, 115, 116],\n",
       " 5596: [5595, 5598, 5597, 5596],\n",
       " 2171: [2172, 2173, 2171],\n",
       " 232: [232],\n",
       " 562: [563, 562, 561],\n",
       " 5908: [5907, 5906, 5908],\n",
       " 1226: [1223, 1225, 1226, 1224],\n",
       " 6465: [6468, 6466, 6467, 6465],\n",
       " 4218: [4217, 4218],\n",
       " 5939: [5936, 5938, 5937, 5939],\n",
       " 5791: [5789, 5790, 5788, 5791],\n",
       " 1230: [1231, 1232, 1230],\n",
       " 3771: [3773, 3772, 3774, 3771],\n",
       " 3622: [3619, 3620, 3621, 3622],\n",
       " 2239: [2240, 2241, 2239],\n",
       " 3517: [3519, 3518, 3517],\n",
       " 763: [761, 762, 763],\n",
       " 2947: [2948, 2949, 2947],\n",
       " 3303: [3302, 3303],\n",
       " 3434: [3433, 3432, 3434],\n",
       " 3283: [3282, 3283],\n",
       " 3343: [3341, 3342, 3343],\n",
       " 6445: [6444, 6445],\n",
       " 938: [938],\n",
       " 2126: [2127, 2126],\n",
       " 4456: [4455, 4456],\n",
       " 2938: [2938, 2939],\n",
       " 1287: [1285, 1284, 1286, 1287],\n",
       " 1546: [1547, 1545, 1544, 1546],\n",
       " 4970: [4972, 4971, 4970],\n",
       " 6032: [6033, 6034, 6031, 6032],\n",
       " 5802: [5799, 5801, 5800, 5802],\n",
       " 286: [284, 287, 286, 285],\n",
       " 565: [564, 566, 565],\n",
       " 4875: [4876, 4874, 4875],\n",
       " 721: [723, 722, 721],\n",
       " 6187: [6188, 6189, 6187],\n",
       " 3351: [3350, 3351],\n",
       " 5207: [5209, 5208, 5210, 5207],\n",
       " 2467: [2468, 2466, 2467],\n",
       " 5426: [5427, 5428, 5425, 5426],\n",
       " 2952: [2950, 2951, 2952],\n",
       " 641: [643, 642, 641, 644],\n",
       " 5313: [5314, 5315, 5312, 5313],\n",
       " 1306: [1304, 1305, 1306],\n",
       " 5502: [5501, 5502],\n",
       " 4892: [4891, 4890, 4889, 4892],\n",
       " 3616: [3618, 3615, 3617, 3616],\n",
       " 5508: [5507, 5508],\n",
       " 1909: [1910, 1908, 1909, 1911],\n",
       " 3721: [3718, 3719, 3720, 3721],\n",
       " 2665: [2666, 2664, 2665],\n",
       " 5961: [5963, 5961, 5962],\n",
       " 3219: [3222, 3221, 3220, 3219],\n",
       " 5322: [5320, 5321, 5322],\n",
       " 413: [412, 414, 413],\n",
       " 2925: [2926, 2925],\n",
       " 4688: [4690, 4689, 4688, 4691],\n",
       " 3273: [3271, 3274, 3272, 3273],\n",
       " 4707: [4708, 4710, 4709, 4707],\n",
       " 4210: [4210],\n",
       " 6183: [6185, 6186, 6184, 6183],\n",
       " 37: [36, 35, 34, 37],\n",
       " 4359: [4359, 4360],\n",
       " 5319: [5316, 5318, 5317, 5319],\n",
       " 4865: [4863, 4864, 4862, 4865],\n",
       " 2672: [2674, 2675, 2673, 2672],\n",
       " 2860: [2860],\n",
       " 2774: [2774],\n",
       " 1635: [1634, 1633, 1632, 1635],\n",
       " 2319: [2320, 2317, 2318, 2319],\n",
       " 5339: [5338, 5339],\n",
       " 2115: [2114, 2115, 2112, 2113],\n",
       " 4592: [4593, 4592],\n",
       " 4423: [4422, 4421, 4424, 4423],\n",
       " 5710: [5712, 5711, 5710],\n",
       " 1693: [1691, 1690, 1692, 1693],\n",
       " 5643: [5644, 5643],\n",
       " 1818: [1820, 1819, 1818],\n",
       " 4428: [4430, 4429, 4427, 4428],\n",
       " 3381: [3378, 3379, 3380, 3381],\n",
       " 1081: [1082, 1083, 1081],\n",
       " 3482: [3481, 3482, 3483],\n",
       " 4849: [4850, 4849, 4851],\n",
       " 4872: [4873, 4870, 4872, 4871],\n",
       " 561: [563, 562, 561],\n",
       " 4618: [4619, 4620, 4618, 4617],\n",
       " 804: [806, 805, 804],\n",
       " 2762: [2761, 2763, 2760, 2762],\n",
       " 5743: [5742, 5743],\n",
       " 3629: [3631, 3630, 3629],\n",
       " 5620: [5619, 5618, 5620],\n",
       " 5585: [5583, 5586, 5584, 5585],\n",
       " 883: [881, 884, 882, 883],\n",
       " 2278: [2279, 2278],\n",
       " 2641: [2640, 2639, 2641],\n",
       " 1636: [1637, 1636],\n",
       " 3485: [3484, 3485],\n",
       " 5287: [5288, 5287],\n",
       " 401: [402, 401],\n",
       " 3223: [3224, 3223],\n",
       " 849: [847, 850, 848, 849],\n",
       " 1523: [1525, 1524, 1523, 1522],\n",
       " 1454: [1452, 1451, 1453, 1454],\n",
       " 2601: [2599, 2600, 2602, 2601],\n",
       " 4609: [4610, 4609],\n",
       " 2954: [2953, 2955, 2954],\n",
       " 3650: [3648, 3649, 3650],\n",
       " 1831: [1833, 1834, 1831, 1832],\n",
       " 2740: [2740],\n",
       " 4493: [4494, 4492, 4495, 4493],\n",
       " 1368: [1369, 1368],\n",
       " 5573: [5572, 5574, 5575, 5573],\n",
       " 911: [910, 912, 911],\n",
       " 818: [816, 817, 818],\n",
       " 5534: [5535, 5533, 5536, 5534],\n",
       " 3812: [3813, 3814, 3812],\n",
       " 3647: [3646, 3647],\n",
       " 5813: [5815, 5816, 5814, 5813],\n",
       " 5926: [5926],\n",
       " 636: [635, 637, 638, 636],\n",
       " 4663: [4664, 4662, 4663],\n",
       " 3713: [3712, 3714, 3713],\n",
       " 201: [200, 199, 201],\n",
       " 2370: [2373, 2371, 2370, 2372],\n",
       " 4133: [4131, 4132, 4133],\n",
       " 3138: [3136, 3139, 3137, 3138],\n",
       " 5520: [5518, 5519, 5521, 5520],\n",
       " 1807: [1807],\n",
       " 1271: [1269, 1270, 1268, 1271],\n",
       " 6162: [6162],\n",
       " 3129: [3126, 3127, 3128, 3129],\n",
       " 2797: [2795, 2796, 2797],\n",
       " 6446: [6447, 6448, 6446],\n",
       " 1281: [1282, 1283, 1281],\n",
       " 879: [878, 877, 880, 879],\n",
       " 533: [533],\n",
       " 5458: [5455, 5456, 5457, 5458],\n",
       " 6141: [6142, 6143, 6140, 6141],\n",
       " 4334: [4332, 4335, 4333, 4334],\n",
       " 609: [610, 612, 611, 609],\n",
       " 2806: [2805, 2806],\n",
       " 5798: [5796, 5797, 5798],\n",
       " 1644: [1643, 1642, 1644],\n",
       " 3080: [3081, 3082, 3080, 3079],\n",
       " 5754: [5755, 5754],\n",
       " 2416: [2418, 2415, 2417, 2416],\n",
       " 1089: [1086, 1087, 1088, 1089],\n",
       " 6225: [6225],\n",
       " 2104: [2104, 2102, 2103],\n",
       " 644: [643, 642, 641, 644],\n",
       " 1123: [1122, 1124, 1121, 1123],\n",
       " 1960: [1959, 1958, 1960, 1957],\n",
       " 1455: [1456, 1457, 1455],\n",
       " 4381: [4382, 4380, 4381],\n",
       " 890: [891, 892, 890],\n",
       " 2341: [2343, 2340, 2342, 2341],\n",
       " 1131: [1132, 1129, 1130, 1131],\n",
       " 708: [709, 710, 707, 708],\n",
       " 1009: [1008, 1010, 1011, 1009],\n",
       " 6083: [6084, 6083, 6082],\n",
       " 3758: [3757, 3758],\n",
       " 2610: [2611, 2609, 2610],\n",
       " 5776: [5777, 5776],\n",
       " 5785: [5787, 5786, 5785],\n",
       " 6284: [6283, 6282, 6284],\n",
       " 2755: [2753, 2754, 2755],\n",
       " 4720: [4721, 4720],\n",
       " 4924: [4925, 4926, 4924, 4923],\n",
       " 4036: [4038, 4035, 4037, 4036],\n",
       " 4291: [4293, 4292, 4290, 4291],\n",
       " 2979: [2979],\n",
       " 3537: [3535, 3538, 3536, 3537],\n",
       " 2294: [2295, 2296, 2297, 2294],\n",
       " 1166: [1167, 1166],\n",
       " 2099: [2101, 2098, 2099, 2100],\n",
       " 2927: [2928, 2927],\n",
       " 4090: [4090],\n",
       " 2023: [2022, 2024, 2021, 2023],\n",
       " 835: [836, 835],\n",
       " 2421: [2420, 2422, 2421],\n",
       " 28: [29, 28],\n",
       " 1046: [1047, 1044, 1045, 1046],\n",
       " 2100: [2101, 2098, 2099, 2100],\n",
       " 4617: [4619, 4620, 4618, 4617],\n",
       " 1970: [1970, 1971],\n",
       " 2243: [2245, 2242, 2244, 2243],\n",
       " 1201: [1200, 1199, 1198, 1201],\n",
       " 378: [379, 378, 380],\n",
       " 2108: [2107, 2108, 2109],\n",
       " 6215: [6214, 6215],\n",
       " 229: [228, 230, 227, 229],\n",
       " 3229: [3230, 3232, 3231, 3229],\n",
       " 1986: [1985, 1983, 1984, 1986],\n",
       " 1330: [1329, 1330],\n",
       " 1938: [1937, 1939, 1938],\n",
       " 627: [627],\n",
       " 4671: [4670, 4672, 4669, 4671],\n",
       " 3836: [3834, 3835, 3836, 3833],\n",
       " 1425: [1424, 1426, 1423, 1425],\n",
       " 6035: [6036, 6038, 6037, 6035],\n",
       " 5505: [5504, 5503, 5505, 5506],\n",
       " 5965: [5964, 5967, 5966, 5965],\n",
       " 1207: [1208, 1207],\n",
       " 2849: [2847, 2850, 2848, 2849],\n",
       " 4188: [4189, 4188],\n",
       " 935: [935],\n",
       " 317: [318, 316, 319, 317],\n",
       " 4443: [4441, 4442, 4443],\n",
       " 2141: [2142, 2141],\n",
       " 2606: [2603, 2605, 2604, 2606],\n",
       " 869: [868, 870, 869],\n",
       " 4315: [4316, 4314, 4317, 4315],\n",
       " 2112: [2114, 2115, 2112, 2113],\n",
       " 780: [779, 782, 781, 780],\n",
       " 6030: [6029, 6028, 6030],\n",
       " 6424: [6425, 6423, 6426, 6424],\n",
       " 3322: [3323, 3324, 3322],\n",
       " 5678: [5677, 5679, 5678],\n",
       " 2289: [2287, 2288, 2289],\n",
       " 6280: [6278, 6281, 6279, 6280],\n",
       " 2662: [2663, 2661, 2660, 2662],\n",
       " 3750: [3749, 3751, 3750],\n",
       " 4729: [4728, 4729],\n",
       " 5062: [5060, 5059, 5061, 5062],\n",
       " 6134: [6132, 6133, 6135, 6134],\n",
       " 3804: [3803, 3802, 3804],\n",
       " 2383: [2384, 2381, 2382, 2383],\n",
       " 3012: [3013, 3012],\n",
       " 6411: [6412, 6410, 6411],\n",
       " 2699: [2697, 2700, 2698, 2699],\n",
       " 6042: [6043, 6041, 6040, 6042],\n",
       " 4920: [4921, 4919, 4922, 4920],\n",
       " 6197: [6198, 6199, 6196, 6197],\n",
       " 1244: [1242, 1243, 1244],\n",
       " 6312: [6312],\n",
       " 2480: [2479, 2481, 2482, 2480],\n",
       " 3052: [3051, 3050, 3053, 3052],\n",
       " 6070: [6072, 6071, 6070],\n",
       " 3466: [3467, 3464, 3466, 3465],\n",
       " 4453: [4454, 4453],\n",
       " 4977: [4978, 4979, 4977],\n",
       " 1511: [1513, 1512, 1511, 1510],\n",
       " 5912: [5913, 5910, 5911, 5912],\n",
       " 2102: [2104, 2102, 2103],\n",
       " 5870: [5867, 5869, 5868, 5870],\n",
       " 3974: [3974],\n",
       " 2009: [2012, 2010, 2011, 2009],\n",
       " 4734: [4735, 4734],\n",
       " 5765: [5766, 5764, 5767, 5765],\n",
       " 1988: [1990, 1987, 1989, 1988],\n",
       " 685: [684, 686, 685],\n",
       " 330: [329, 328, 330],\n",
       " 1444: [1445, 1446, 1444],\n",
       " 3162: [3162],\n",
       " 2985: [2984, 2985],\n",
       " 3958: [3960, 3961, 3958, 3959],\n",
       " 856: [855, 856],\n",
       " 5241: [5242, 5240, 5241],\n",
       " 2738: [2737, 2739, 2738],\n",
       " 5486: [5487, 5484, 5485, 5486],\n",
       " 5864: [5863, 5865, 5864, 5866],\n",
       " 3465: [3467, 3464, 3466, 3465],\n",
       " 3002: [3004, 3003, 3002],\n",
       " 5494: [5493, 5492, 5494],\n",
       " 43: [42, 43],\n",
       " 2302: [2301, 2302],\n",
       " 4923: [4925, 4926, 4924, 4923],\n",
       " 552: [551, 550, 549, 552],\n",
       " 380: [379, 378, 380],\n",
       " 4403: [4404, 4402, 4403],\n",
       " 925: [924, 926, 925],\n",
       " 2471: [2469, 2472, 2470, 2471],\n",
       " 1720: [1722, 1719, 1720, 1721],\n",
       " 5623: [5624, 5626, 5625, 5623],\n",
       " 1891: [1893, 1892, 1891],\n",
       " 5985: [5987, 5986, 5988, 5985],\n",
       " 725: [727, 726, 725],\n",
       " 1371: [1370, 1371],\n",
       " 389: [387, 388, 389],\n",
       " 2744: [2746, 2743, 2745, 2744],\n",
       " 645: [646, 645],\n",
       " 3691: [3690, 3692, 3691],\n",
       " 5237: [5239, 5238, 5236, 5237],\n",
       " 4537: [4538, 4539, 4537],\n",
       " 2401: [2400, 2399, 2402, 2401],\n",
       " 1662: [1660, 1663, 1661, 1662],\n",
       " 3025: [3026, 3027, 3028, 3025],\n",
       " 909: [907, 908, 909],\n",
       " 3858: [3857, 3858],\n",
       " 4001: [4000, 4002, 4001],\n",
       " 5399: [5398, 5401, 5400, 5399],\n",
       " 6006: [6005, 6006],\n",
       " 5021: [5020, 5021],\n",
       " 2722: [2721, 2722],\n",
       " 5830: [5828, 5829, 5831, 5830],\n",
       " 603: [603],\n",
       " 1785: [1783, 1784, 1785],\n",
       " 4141: [4139, 4140, 4141],\n",
       " 3170: [3169, 3168, 3170],\n",
       " 4250: [4251, 4252, 4250],\n",
       " 3483: [3481, 3482, 3483],\n",
       " 4871: [4873, 4870, 4872, 4871],\n",
       " 5995: [5992, 5993, 5994, 5995],\n",
       " 3722: [3722],\n",
       " 5488: [5489, 5491, 5490, 5488],\n",
       " 4245: [4243, 4242, 4244, 4245],\n",
       " 2246: [2249, 2247, 2248, 2246],\n",
       " 1721: [1722, 1719, 1720, 1721],\n",
       " 6211: [6213, 6212, 6211],\n",
       " 4737: [4738, 4736, 4737],\n",
       " 4255: [4253, 4254, 4255],\n",
       " 5588: [5587, 5588],\n",
       " 5413: [5412, 5414, 5413],\n",
       " 166: [165, 164, 166],\n",
       " 4064: [4063, 4065, 4064],\n",
       " 4116: [4117, 4116, 4118],\n",
       " 5164: [5165, 5167, 5166, 5164],\n",
       " 2347: [2349, 2348, 2350, 2347],\n",
       " 1312: [1313, 1312],\n",
       " 1696: [1694, 1697, 1695, 1696],\n",
       " 4691: [4690, 4689, 4688, 4691],\n",
       " 368: [366, 365, 367, 368],\n",
       " 4657: [4657],\n",
       " 4834: [4833, 4835, 4834],\n",
       " 6069: [6067, 6068, 6069],\n",
       " 4651: [4653, 4652, 4651],\n",
       " 1350: [1347, 1349, 1348, 1350],\n",
       " 1149: [1150, 1151, 1149],\n",
       " 2703: [2702, 2704, 2701, 2703],\n",
       " 4578: [4579, 4576, 4577, 4578],\n",
       " 226: [225, 223, 224, 226],\n",
       " 1502: [1503, 1502],\n",
       " 6350: [6349, 6350],\n",
       " 2751: [2750, 2752, 2751],\n",
       " 1997: [1994, 1995, 1997, 1996],\n",
       " 1596: [1597, 1595, 1596],\n",
       " 5753: [5752, 5751, 5753],\n",
       " 3426: [3427, 3425, 3424, 3426],\n",
       " 4693: [4692, 4694, 4693],\n",
       " 2372: [2373, 2371, 2370, 2372],\n",
       " 4976: [4974, 4975, 4973, 4976],\n",
       " 3854: [3855, 3856, 3854],\n",
       " 1522: [1525, 1524, 1523, 1522],\n",
       " 4480: [4479, 4480],\n",
       " 1410: [1409, 1410],\n",
       " 1379: [1378, 1380, 1379],\n",
       " 163: [162, 161, 163],\n",
       " 4281: [4280, 4283, 4282, 4281],\n",
       " 1982: [1981, 1979, 1980, 1982],\n",
       " 5441: [5442, 5443, 5441],\n",
       " 536: [536],\n",
       " 6232: [6232],\n",
       " 6082: [6084, 6083, 6082],\n",
       " 1553: [1554, 1552, 1553],\n",
       " 2353: [2351, 2352, 2354, 2353],\n",
       " 2020: [2018, 2019, 2017, 2020],\n",
       " 4384: [4385, 4383, 4386, 4384],\n",
       " 1875: [1874, 1873, 1872, 1875],\n",
       " 1372: [1374, 1373, 1372],\n",
       " 4965: [4964, 4965],\n",
       " 2113: [2114, 2115, 2112, 2113],\n",
       " 898: [897, 899, 898],\n",
       " 5472: [5473, 5474, 5475, 5472],\n",
       " 494: [495, 494],\n",
       " 348: [348],\n",
       " 2257: [2256, 2257],\n",
       " 2074: [2072, 2073, 2074],\n",
       " 3699: [3698, 3697, 3700, 3699],\n",
       " 3079: [3081, 3082, 3080, 3079],\n",
       " 3725: [3726, 3724, 3725],\n",
       " 4256: [4256],\n",
       " 4062: [4062],\n",
       " 1060: [1059, 1058, 1060],\n",
       " 3987: [3989, 3988, 3987],\n",
       " 1224: [1223, 1225, 1226, 1224],\n",
       " 663: [664, 662, 663],\n",
       " 2510: [2511, 2509, 2512, 2510],\n",
       " 989: [987, 990, 988, 989],\n",
       " 4337: [4336, 4338, 4339, 4337],\n",
       " 5920: [5921, 5922, 5920],\n",
       " 2103: [2104, 2102, 2103],\n",
       " 70: [72, 71, 70],\n",
       " 5666: [5664, 5665, 5667, 5666],\n",
       " 4851: [4850, 4849, 4851],\n",
       " 5460: [5461, 5459, 5460],\n",
       " 1295: [1294, 1296, 1295],\n",
       " 1832: [1833, 1834, 1831, 1832],\n",
       " 5860: [5861, 5862, 5860],\n",
       " 6079: [6080, 6078, 6081, 6079],\n",
       " 6287: [6285, 6286, 6287],\n",
       " 4824: [4824],\n",
       " 3287: [3289, 3288, 3290, 3287],\n",
       " 1255: [1254, 1253, 1255],\n",
       " 5826: [5825, 5827, 5826],\n",
       " 4507: [4508, 4507],\n",
       " 3689: [3688, 3689],\n",
       " 4783: [4782, 4784, 4783],\n",
       " 632: [634, 633, 632],\n",
       " 5263: [5264, 5263],\n",
       " 1578: [1579, 1577, 1576, 1578],\n",
       " 5379: [5378, 5377, 5379],\n",
       " 1190: [1189, 1192, 1191, 1190],\n",
       " 2590: [2591, 2590],\n",
       " 304: [303, 302, 304],\n",
       " 172: [171, 173, 174, 172],\n",
       " 827: [827],\n",
       " 4677: [4679, 4678, 4677],\n",
       " 5669: [5671, 5668, 5670, 5669],\n",
       " 4360: [4359, 4360],\n",
       " 3382: [3383, 3382],\n",
       " 238: [239, 237, 238],\n",
       " 1957: [1959, 1958, 1960, 1957],\n",
       " 183: [184, 183],\n",
       " 3360: [3359, 3357, 3360, 3358],\n",
       " 4212: [4213, 4211, 4214, 4212],\n",
       " 530: [531, 529, 532, 530],\n",
       " 3160: [3161, 3160],\n",
       " 124: [125, 123, 124],\n",
       " 3321: [3321],\n",
       " 2905: [2906, 2904, 2905],\n",
       " 6341: [6340, 6339, 6342, 6341],\n",
       " 3103: [3105, 3104, 3103],\n",
       " 3962: [3963, 3962],\n",
       " 1996: [1994, 1995, 1997, 1996],\n",
       " 5506: [5504, 5503, 5505, 5506],\n",
       " 5888: [5887, 5888],\n",
       " 1659: [1657, 1658, 1659],\n",
       " 3831: [3832, 3830, 3831],\n",
       " 5962: [5963, 5961, 5962],\n",
       " 420: [419, 418, 420],\n",
       " 569: [569],\n",
       " 7: [7],\n",
       " 2026: [2025, 2026],\n",
       " 2163: [2162, 2163],\n",
       " 1840: [1841, 1842, 1840],\n",
       " 3474: [3475, 3473, 3474],\n",
       " 3817: [3816, 3815, 3818, 3817],\n",
       " 5725: [5722, 5723, 5724, 5725],\n",
       " 5304: [5303, 5302, 5304],\n",
       " 4048: [4047, 4048],\n",
       " 3134: [3133, 3135, 3134],\n",
       " 1865: [1864, 1865],\n",
       " 1971: [1970, 1971],\n",
       " 110: [111, 108, 109, 110],\n",
       " 2584: [2583, 2582, 2584],\n",
       " 2809: [2807, 2808, 2809],\n",
       " 1940: [1941, 1940],\n",
       " 4248: [4249, 4248],\n",
       " 1733: [1734, 1733],\n",
       " 785: [784, 783, 785],\n",
       " 671: [670, 672, 671],\n",
       " 6003: [6004, 6003],\n",
       " 1392: [1393, 1392],\n",
       " 206: [207, 206],\n",
       " 1030: [1032, 1031, 1029, 1030],\n",
       " 2109: [2107, 2108, 2109],\n",
       " 5900: [5899, 5898, 5900],\n",
       " 3024: [3023, 3024],\n",
       " 5090: [5091, 5092, 5093, 5090],\n",
       " 3132: [3131, 3130, 3132],\n",
       " 4767: [4768, 4769, 4766, 4767],\n",
       " 3599: [3600, 3598, 3599],\n",
       " 1510: [1513, 1512, 1511, 1510],\n",
       " 5003: [5000, 5002, 5001, 5003],\n",
       " 4118: [4117, 4116, 4118],\n",
       " 1038: [1039, 1038],\n",
       " 2692: [2693, 2691, 2690, 2692],\n",
       " 2748: [2749, 2747, 2748],\n",
       " 2756: [2759, 2757, 2758, 2756],\n",
       " 1104: [1103, 1105, 1102, 1104],\n",
       " 3254: [3253, 3254],\n",
       " 6401: [6400, 6399, 6401],\n",
       " 3765: [3767, 3764, 3766, 3765],\n",
       " 5989: [5991, 5990, 5989],\n",
       " 2846: [2845, 2846],\n",
       " 5891: [5889, 5890, 5891],\n",
       " 950: [950],\n",
       " 3959: [3960, 3961, 3958, 3959],\n",
       " 5023: [5025, 5024, 5023],\n",
       " 4895: [4893, 4894, 4895],\n",
       " 2123: [2122, 2120, 2121, 2123],\n",
       " 5120: [5121, 5120],\n",
       " 4400: [4401, 4399, 4400],\n",
       " 1307: [1309, 1308, 1307],\n",
       " 14: [15, 12, 13, 14],\n",
       " 793: [793, 792],\n",
       " 3569: [3571, 3572, 3570, 3569],\n",
       " 285: [284, 287, 286, 285],\n",
       " 3358: [3359, 3357, 3360, 3358],\n",
       " 3833: [3834, 3835, 3836, 3833],\n",
       " 6269: [6270, 6269],\n",
       " 1535: [1536, 1535],\n",
       " 3479: [3478, 3480, 3479],\n",
       " 4599: [4600, 4601, 4599],\n",
       " 5866: [5863, 5865, 5864, 5866],\n",
       " 6404: [6405, 6407, 6406, 6404],\n",
       " 2889: [2888, 2889],\n",
       " 2802: [2803, 2804, 2802],\n",
       " 2940: [2940],\n",
       " 1911: [1910, 1908, 1909, 1911],\n",
       " 5909: [5909],\n",
       " 1520: [1521, 1520],\n",
       " 5698: [5697, 5698],\n",
       " 306: [307, 308, 305, 306],\n",
       " 2815: [2814, 2813, 2815],\n",
       " 3654: [3655, 3654],\n",
       " 2794: [2793, 2792, 2794],\n",
       " 2997: [2998, 2997],\n",
       " 2462: [2463, 2464, 2465, 2462],\n",
       " 5432: [5430, 5431, 5429, 5432],\n",
       " 6106: [6105, 6106],\n",
       " 3280: [3281, 3279, 3280],\n",
       " 1560: [1561, 1559, 1562, 1560],\n",
       " 2139: [2138, 2137, 2139],\n",
       " 3156: [3157, 3159, 3158, 3156],\n",
       " 3143: [3144, 3146, 3145, 3143],\n",
       " 5184: [5183, 5185, 5184],\n",
       " 4055: [4056, 4057, 4055],\n",
       " 1699: [1700, 1699],\n",
       " 3809: [3808, 3810, 3811, 3809],\n",
       " 5233: [5235, 5234, 5233],\n",
       " 6310: [6309, 6311, 6310],\n",
       " 1036: [1035, 1037, 1036],\n",
       " 5202: [5201, 5199, 5200, 5202],\n",
       " 6226: [6228, 6227, 6226],\n",
       " 1109: [1111, 1110, 1109],\n",
       " 3093: [3092, 3093],\n",
       " 3403: [3405, 3404, 3403],\n",
       " 2559: [2562, 2561, 2560, 2559],\n",
       " 4082: [4084, 4083, 4082],\n",
       " 6055: [6053, 6052, 6054, 6055],\n",
       " 3829: [3828, 3829],\n",
       " 4370: [4369, 4370],\n",
       " 5088: [5089, 5087, 5088],\n",
       " 4371: [4372, 4374, 4373, 4371],\n",
       " 4627: [4626, 4625, 4627],\n",
       " 2939: [2938, 2939],\n",
       " 137: [138, 137],\n",
       " 2432: [2430, 2429, 2431, 2432],\n",
       " 3461: [3460, 3461],\n",
       " 792: [793, 792],\n",
       " 2883: [2880, 2881, 2882, 2883],\n",
       " 1610: [1609, 1611, 1610],\n",
       " 669: [668, 669],\n",
       " 2389: [2391, 2390, 2388, 2389],\n",
       " 2153: [2154, 2152, 2153],\n",
       " 4650: [4649, 4648, 4650],\n",
       " 6155: [6153, 6154, 6152, 6155],\n",
       " 3938: [3939, 3940, 3938]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevant_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d4655b04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['global_chunk_id', 'positive', 'anchor', 'id'],\n",
       "    num_rows: 647\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "88eb998b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['global_chunk_id', 'positive', 'anchor', 'id'],\n",
       "    num_rows: 6469\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2d141ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimensions of interest\n",
    "matryoshka_dimensions = [768, 512, 256, 128, 64] # Important: large to small\n",
    "\n",
    "# Create empty list to hold evaluators\n",
    "matryoshka_evaluators = []\n",
    "\n",
    "# Create an evaluator for each above dimension\n",
    "for dim in matryoshka_dimensions:\n",
    "    # Define the evaluator\n",
    "    ir_evaluator = InformationRetrievalEvaluator(\n",
    "        queries=queries,\n",
    "        corpus=corpus,\n",
    "        relevant_docs=relevant_docs,\n",
    "        name=f\"dim_{dim}\",\n",
    "        truncate_dim=dim,  # Truncate the embeddings to the respective dimension\n",
    "        score_functions={\"cosine\": cos_sim},\n",
    "    )\n",
    "    # Add to list\n",
    "    matryoshka_evaluators.append(ir_evaluator)\n",
    "\n",
    "# Create a sequential evaluator\n",
    "# Able to run all our dimension specific InformationRetrievalEvaluators sequentially.\n",
    "evaluator = SequentialEvaluator(matryoshka_evaluators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1dd719f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<sentence_transformers.evaluation.InformationRetrievalEvaluator.InformationRetrievalEvaluator at 0x28b2ae91210>,\n",
       " <sentence_transformers.evaluation.InformationRetrievalEvaluator.InformationRetrievalEvaluator at 0x28b2adef7d0>,\n",
       " <sentence_transformers.evaluation.InformationRetrievalEvaluator.InformationRetrievalEvaluator at 0x28b2adeef10>,\n",
       " <sentence_transformers.evaluation.InformationRetrievalEvaluator.InformationRetrievalEvaluator at 0x28b2bd860d0>,\n",
       " <sentence_transformers.evaluation.InformationRetrievalEvaluator.InformationRetrievalEvaluator at 0x28b2ae9d0d0>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matryoshka_evaluators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0663b9c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Base Model Evaluation Results\n",
      "-------------------------------------------------------------------------------------\n",
      "Metric                  768d         512d         256d         128d          64d\n",
      "-------------------------------------------------------------------------------------\n",
      "==ndcg@10==            0.4291       0.4233       0.4075       0.3679       0.2538 \n",
      "mrr@10                 0.3758       0.3717       0.3553       0.3176       0.2151 \n",
      "map@100                0.4205       0.4153       0.3987       0.3586       0.2531 \n",
      "accuracy@1             0.3323       0.3261       0.3107       0.2751       0.1839 \n",
      "accuracy@3             0.3740       0.3802       0.3586       0.3184       0.2117 \n",
      "accuracy@5             0.4467       0.4513       0.4359       0.3833       0.2658 \n",
      "accuracy@10            0.5348       0.5178       0.5085       0.4699       0.3338 \n",
      "precision@1            0.3323       0.3261       0.3107       0.2751       0.1839 \n",
      "precision@3            0.3148       0.3153       0.2978       0.2664       0.1721 \n",
      "precision@5            0.2457       0.2482       0.2399       0.2117       0.1422 \n",
      "precision@10           0.1592       0.1549       0.1512       0.1391       0.0954 \n",
      "recall@1               0.1243       0.1216       0.1151       0.1014       0.0720 \n",
      "recall@3               0.3206       0.3225       0.3027       0.2715       0.1783 \n",
      "recall@5               0.4046       0.4119       0.3950       0.3512       0.2405 \n",
      "recall@10              0.5185       0.5077       0.4942       0.4522       0.3214 \n",
      "-------------------------------------------------------------------------------------\n",
      "seq_score: 0.253799\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "base_results = evaluator(model)\n",
    "\n",
    "# Print header\n",
    "print(\"\\nBase Model Evaluation Results\")\n",
    "print(\"-\" * 85)\n",
    "print(f\"{'Metric':15} {'768d':>12} {'512d':>12} {'256d':>12} {'128d':>12} {'64d':>12}\")\n",
    "print(\"-\" * 85)\n",
    "\n",
    "# List of metrics to display\n",
    "metrics = [\n",
    "    'ndcg@10',\n",
    "    'mrr@10',\n",
    "    'map@100',\n",
    "    'accuracy@1',\n",
    "    'accuracy@3',\n",
    "    'accuracy@5',\n",
    "    'accuracy@10',\n",
    "    'precision@1',\n",
    "    'precision@3',\n",
    "    'precision@5',\n",
    "    'precision@10',\n",
    "    'recall@1',\n",
    "    'recall@3',\n",
    "    'recall@5',\n",
    "    'recall@10'\n",
    "]\n",
    "\n",
    "# Print each metric\n",
    "for metric in metrics:\n",
    "    values = []\n",
    "    for dim in matryoshka_dimensions:\n",
    "        key = f\"dim_{dim}_cosine_{metric}\"\n",
    "        values.append(base_results[key])\n",
    "\n",
    "    # Highlight NDCG@10\n",
    "    metric_name = f\"=={metric}==\" if metric == \"ndcg@10\" else metric\n",
    "    print(f\"{metric_name:15}\", end=\"  \")\n",
    "    for val in values:\n",
    "        print(f\"{val:12.4f}\", end=\" \")\n",
    "    print()\n",
    "\n",
    "# Print sequential score\n",
    "print(\"-\" * 85)\n",
    "print(f\"{'seq_score:'} {base_results['sequential_score']:1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "52f88019",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dim_768_cosine_accuracy@1': 0.3323029366306028,\n",
       " 'dim_768_cosine_accuracy@3': 0.3740340030911901,\n",
       " 'dim_768_cosine_accuracy@5': 0.446676970633694,\n",
       " 'dim_768_cosine_accuracy@10': 0.5347758887171561,\n",
       " 'dim_768_cosine_precision@1': 0.3323029366306028,\n",
       " 'dim_768_cosine_precision@3': 0.31478619268418345,\n",
       " 'dim_768_cosine_precision@5': 0.24574961360123648,\n",
       " 'dim_768_cosine_precision@10': 0.15919629057187018,\n",
       " 'dim_768_cosine_recall@1': 0.12429160226687273,\n",
       " 'dim_768_cosine_recall@3': 0.3205821741370427,\n",
       " 'dim_768_cosine_recall@5': 0.4045595054095827,\n",
       " 'dim_768_cosine_recall@10': 0.51854714064915,\n",
       " 'dim_768_cosine_ndcg@10': 0.4291462710200361,\n",
       " 'dim_768_cosine_mrr@10': 0.37576298422511695,\n",
       " 'dim_768_cosine_map@100': 0.4205064770071176,\n",
       " 'dim_512_cosine_accuracy@1': 0.3261205564142195,\n",
       " 'dim_512_cosine_accuracy@3': 0.3802163833075734,\n",
       " 'dim_512_cosine_accuracy@5': 0.45131375579598143,\n",
       " 'dim_512_cosine_accuracy@10': 0.517774343122102,\n",
       " 'dim_512_cosine_precision@1': 0.3261205564142195,\n",
       " 'dim_512_cosine_precision@3': 0.31530139103554866,\n",
       " 'dim_512_cosine_precision@5': 0.2482225656877898,\n",
       " 'dim_512_cosine_precision@10': 0.15486862442040186,\n",
       " 'dim_512_cosine_recall@1': 0.12158681092220504,\n",
       " 'dim_512_cosine_recall@3': 0.32251416795466253,\n",
       " 'dim_512_cosine_recall@5': 0.41190108191653785,\n",
       " 'dim_512_cosine_recall@10': 0.5077279752704791,\n",
       " 'dim_512_cosine_ndcg@10': 0.4233151326889703,\n",
       " 'dim_512_cosine_mrr@10': 0.37169046392384864,\n",
       " 'dim_512_cosine_map@100': 0.4153359359335017,\n",
       " 'dim_256_cosine_accuracy@1': 0.3106646058732612,\n",
       " 'dim_256_cosine_accuracy@3': 0.35857805255023184,\n",
       " 'dim_256_cosine_accuracy@5': 0.43585780525502316,\n",
       " 'dim_256_cosine_accuracy@10': 0.508500772797527,\n",
       " 'dim_256_cosine_precision@1': 0.3106646058732612,\n",
       " 'dim_256_cosine_precision@3': 0.2977846470891293,\n",
       " 'dim_256_cosine_precision@5': 0.23987635239567237,\n",
       " 'dim_256_cosine_precision@10': 0.1511591962905719,\n",
       " 'dim_256_cosine_recall@1': 0.1151468315301391,\n",
       " 'dim_256_cosine_recall@3': 0.3026790314270994,\n",
       " 'dim_256_cosine_recall@5': 0.39502833590932507,\n",
       " 'dim_256_cosine_recall@10': 0.49420401854714063,\n",
       " 'dim_256_cosine_ndcg@10': 0.4074784092074726,\n",
       " 'dim_256_cosine_mrr@10': 0.35533414293074245,\n",
       " 'dim_256_cosine_map@100': 0.3986606471747957,\n",
       " 'dim_128_cosine_accuracy@1': 0.2751159196290572,\n",
       " 'dim_128_cosine_accuracy@3': 0.31839258114374036,\n",
       " 'dim_128_cosine_accuracy@5': 0.38330757341576505,\n",
       " 'dim_128_cosine_accuracy@10': 0.46986089644513135,\n",
       " 'dim_128_cosine_precision@1': 0.2751159196290572,\n",
       " 'dim_128_cosine_precision@3': 0.26635754765584746,\n",
       " 'dim_128_cosine_precision@5': 0.2117465224111283,\n",
       " 'dim_128_cosine_precision@10': 0.1391035548686244,\n",
       " 'dim_128_cosine_recall@1': 0.10136527563111797,\n",
       " 'dim_128_cosine_recall@3': 0.2715095311695002,\n",
       " 'dim_128_cosine_recall@5': 0.3512364760432767,\n",
       " 'dim_128_cosine_recall@10': 0.45221535291087067,\n",
       " 'dim_128_cosine_ndcg@10': 0.3679167153333985,\n",
       " 'dim_128_cosine_mrr@10': 0.3176498368538553,\n",
       " 'dim_128_cosine_map@100': 0.3585966107540825,\n",
       " 'dim_64_cosine_accuracy@1': 0.1839258114374034,\n",
       " 'dim_64_cosine_accuracy@3': 0.2117465224111283,\n",
       " 'dim_64_cosine_accuracy@5': 0.26584234930448225,\n",
       " 'dim_64_cosine_accuracy@10': 0.33384853168469864,\n",
       " 'dim_64_cosine_precision@1': 0.1839258114374034,\n",
       " 'dim_64_cosine_precision@3': 0.17207624935600205,\n",
       " 'dim_64_cosine_precision@5': 0.14219474497681608,\n",
       " 'dim_64_cosine_precision@10': 0.09536321483771253,\n",
       " 'dim_64_cosine_recall@1': 0.07199896960329726,\n",
       " 'dim_64_cosine_recall@3': 0.17825862957238534,\n",
       " 'dim_64_cosine_recall@5': 0.24046883049974238,\n",
       " 'dim_64_cosine_recall@10': 0.32135497166409066,\n",
       " 'dim_64_cosine_ndcg@10': 0.25379877283252333,\n",
       " 'dim_64_cosine_mrr@10': 0.21510144500870934,\n",
       " 'dim_64_cosine_map@100': 0.25310613455281994,\n",
       " 'sequential_score': 0.25379877283252333}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_results \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9f64f9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model with SDPA for using Flash Attention 2\n",
    "model = SentenceTransformer(\n",
    "    model_id,\n",
    "    model_kwargs={\"attn_implementation\": \"sdpa\"},\n",
    "    model_card_data=SentenceTransformerModelCardData(\n",
    "        language=\"en\",\n",
    "        license=\"apache-2.0\",\n",
    "        model_name=\"ModernBERT Embed base Legal Matryoshka\",\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "723d2d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial Loss\n",
    "base_loss = MultipleNegativesRankingLoss(model)\n",
    "\n",
    "# Matryoshka Loss Wrapper\n",
    "train_loss = MatryoshkaLoss(\n",
    "    model, base_loss, matryoshka_dims=matryoshka_dimensions\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "90dc37f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = SentenceTransformerTrainingArguments(\n",
    "    output_dir=\"modernbert-embed-base-legal-matryoshka-lucek\", # output directory and hugging face model ID\n",
    "    num_train_epochs=4,                                        # number of epochs\n",
    "    per_device_train_batch_size=32,                            # train batch size\n",
    "    gradient_accumulation_steps=16,                            # for a global batch size of 512\n",
    "    per_device_eval_batch_size=16,                             # evaluation batch size\n",
    "    warmup_ratio=0.1,                                          # warmup ratio\n",
    "    learning_rate=2e-5,                                        # learning rate, 2e-5 is a good value\n",
    "    lr_scheduler_type=\"cosine\",                                # use cosine learning rate scheduler\n",
    "    optim=\"adamw_torch_fused\",                                 # use fused adamw optimizer\n",
    "    tf32=True,                                                 # use tf32 precision\n",
    "    bf16=True,                                                 # use bf16 precision\n",
    "    batch_sampler=BatchSamplers.NO_DUPLICATES,                 # MultipleNegativesRankingLoss benefits from no duplicate samples in a batch\n",
    "    eval_strategy=\"epoch\",                                     # evaluate after each epoch\n",
    "    save_strategy=\"epoch\",                                     # save after each epoch\n",
    "    logging_steps=10,                                          # log every 10 steps\n",
    "    save_total_limit=3,                                        # save only the last 3 models\n",
    "    load_best_model_at_end=True,                               # load the best model when training ends\n",
    "    metric_for_best_model=\"eval_dim_128_cosine_ndcg@10\",       # Optimizing for the best ndcg@10 score for the 128 dimension\n",
    "    report_to=\"none\"                                           # Turning off training logging for now, input 'wandb' etc. if desired.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "04e03ff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    }
   ],
   "source": [
    "trainer = SentenceTransformerTrainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=train_dataset.select_columns(\n",
    "        [\"positive\", \"anchor\"]\n",
    "    ),  # training dataset\n",
    "    loss=train_loss,\n",
    "    evaluator=evaluator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "722909fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Column 'anchor' is at index 1, whereas a column with this name is usually expected at index 0. Note that the column order can be important for some losses, e.g. MultipleNegativesRankingLoss will always consider the first column as the anchor and the second as the positive, regardless of the dataset column names. Consider renaming the columns to match the expected order, e.g.:\n",
      "dataset = dataset.select_columns(['anchor', 'positive', 'negative'])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='48' max='48' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [48/48 33:06, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Dim 768 Cosine Accuracy@1</th>\n",
       "      <th>Dim 768 Cosine Accuracy@3</th>\n",
       "      <th>Dim 768 Cosine Accuracy@5</th>\n",
       "      <th>Dim 768 Cosine Accuracy@10</th>\n",
       "      <th>Dim 768 Cosine Precision@1</th>\n",
       "      <th>Dim 768 Cosine Precision@3</th>\n",
       "      <th>Dim 768 Cosine Precision@5</th>\n",
       "      <th>Dim 768 Cosine Precision@10</th>\n",
       "      <th>Dim 768 Cosine Recall@1</th>\n",
       "      <th>Dim 768 Cosine Recall@3</th>\n",
       "      <th>Dim 768 Cosine Recall@5</th>\n",
       "      <th>Dim 768 Cosine Recall@10</th>\n",
       "      <th>Dim 768 Cosine Ndcg@10</th>\n",
       "      <th>Dim 768 Cosine Mrr@10</th>\n",
       "      <th>Dim 768 Cosine Map@100</th>\n",
       "      <th>Dim 512 Cosine Accuracy@1</th>\n",
       "      <th>Dim 512 Cosine Accuracy@3</th>\n",
       "      <th>Dim 512 Cosine Accuracy@5</th>\n",
       "      <th>Dim 512 Cosine Accuracy@10</th>\n",
       "      <th>Dim 512 Cosine Precision@1</th>\n",
       "      <th>Dim 512 Cosine Precision@3</th>\n",
       "      <th>Dim 512 Cosine Precision@5</th>\n",
       "      <th>Dim 512 Cosine Precision@10</th>\n",
       "      <th>Dim 512 Cosine Recall@1</th>\n",
       "      <th>Dim 512 Cosine Recall@3</th>\n",
       "      <th>Dim 512 Cosine Recall@5</th>\n",
       "      <th>Dim 512 Cosine Recall@10</th>\n",
       "      <th>Dim 512 Cosine Ndcg@10</th>\n",
       "      <th>Dim 512 Cosine Mrr@10</th>\n",
       "      <th>Dim 512 Cosine Map@100</th>\n",
       "      <th>Dim 256 Cosine Accuracy@1</th>\n",
       "      <th>Dim 256 Cosine Accuracy@3</th>\n",
       "      <th>Dim 256 Cosine Accuracy@5</th>\n",
       "      <th>Dim 256 Cosine Accuracy@10</th>\n",
       "      <th>Dim 256 Cosine Precision@1</th>\n",
       "      <th>Dim 256 Cosine Precision@3</th>\n",
       "      <th>Dim 256 Cosine Precision@5</th>\n",
       "      <th>Dim 256 Cosine Precision@10</th>\n",
       "      <th>Dim 256 Cosine Recall@1</th>\n",
       "      <th>Dim 256 Cosine Recall@3</th>\n",
       "      <th>Dim 256 Cosine Recall@5</th>\n",
       "      <th>Dim 256 Cosine Recall@10</th>\n",
       "      <th>Dim 256 Cosine Ndcg@10</th>\n",
       "      <th>Dim 256 Cosine Mrr@10</th>\n",
       "      <th>Dim 256 Cosine Map@100</th>\n",
       "      <th>Dim 128 Cosine Accuracy@1</th>\n",
       "      <th>Dim 128 Cosine Accuracy@3</th>\n",
       "      <th>Dim 128 Cosine Accuracy@5</th>\n",
       "      <th>Dim 128 Cosine Accuracy@10</th>\n",
       "      <th>Dim 128 Cosine Precision@1</th>\n",
       "      <th>Dim 128 Cosine Precision@3</th>\n",
       "      <th>Dim 128 Cosine Precision@5</th>\n",
       "      <th>Dim 128 Cosine Precision@10</th>\n",
       "      <th>Dim 128 Cosine Recall@1</th>\n",
       "      <th>Dim 128 Cosine Recall@3</th>\n",
       "      <th>Dim 128 Cosine Recall@5</th>\n",
       "      <th>Dim 128 Cosine Recall@10</th>\n",
       "      <th>Dim 128 Cosine Ndcg@10</th>\n",
       "      <th>Dim 128 Cosine Mrr@10</th>\n",
       "      <th>Dim 128 Cosine Map@100</th>\n",
       "      <th>Dim 64 Cosine Accuracy@1</th>\n",
       "      <th>Dim 64 Cosine Accuracy@3</th>\n",
       "      <th>Dim 64 Cosine Accuracy@5</th>\n",
       "      <th>Dim 64 Cosine Accuracy@10</th>\n",
       "      <th>Dim 64 Cosine Precision@1</th>\n",
       "      <th>Dim 64 Cosine Precision@3</th>\n",
       "      <th>Dim 64 Cosine Precision@5</th>\n",
       "      <th>Dim 64 Cosine Precision@10</th>\n",
       "      <th>Dim 64 Cosine Recall@1</th>\n",
       "      <th>Dim 64 Cosine Recall@3</th>\n",
       "      <th>Dim 64 Cosine Recall@5</th>\n",
       "      <th>Dim 64 Cosine Recall@10</th>\n",
       "      <th>Dim 64 Cosine Ndcg@10</th>\n",
       "      <th>Dim 64 Cosine Mrr@10</th>\n",
       "      <th>Dim 64 Cosine Map@100</th>\n",
       "      <th>Sequential Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>5.758900</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.514683</td>\n",
       "      <td>0.561051</td>\n",
       "      <td>0.638331</td>\n",
       "      <td>0.710974</td>\n",
       "      <td>0.514683</td>\n",
       "      <td>0.479134</td>\n",
       "      <td>0.365379</td>\n",
       "      <td>0.215611</td>\n",
       "      <td>0.192942</td>\n",
       "      <td>0.484802</td>\n",
       "      <td>0.597115</td>\n",
       "      <td>0.697965</td>\n",
       "      <td>0.612262</td>\n",
       "      <td>0.558969</td>\n",
       "      <td>0.599847</td>\n",
       "      <td>0.505410</td>\n",
       "      <td>0.537867</td>\n",
       "      <td>0.627512</td>\n",
       "      <td>0.695518</td>\n",
       "      <td>0.505410</td>\n",
       "      <td>0.463163</td>\n",
       "      <td>0.354250</td>\n",
       "      <td>0.210665</td>\n",
       "      <td>0.190881</td>\n",
       "      <td>0.469603</td>\n",
       "      <td>0.579727</td>\n",
       "      <td>0.682895</td>\n",
       "      <td>0.598293</td>\n",
       "      <td>0.546265</td>\n",
       "      <td>0.587033</td>\n",
       "      <td>0.469861</td>\n",
       "      <td>0.514683</td>\n",
       "      <td>0.595054</td>\n",
       "      <td>0.667697</td>\n",
       "      <td>0.469861</td>\n",
       "      <td>0.437403</td>\n",
       "      <td>0.336631</td>\n",
       "      <td>0.201855</td>\n",
       "      <td>0.177615</td>\n",
       "      <td>0.445131</td>\n",
       "      <td>0.554740</td>\n",
       "      <td>0.654688</td>\n",
       "      <td>0.568178</td>\n",
       "      <td>0.514278</td>\n",
       "      <td>0.555952</td>\n",
       "      <td>0.369397</td>\n",
       "      <td>0.428130</td>\n",
       "      <td>0.508501</td>\n",
       "      <td>0.587326</td>\n",
       "      <td>0.369397</td>\n",
       "      <td>0.355487</td>\n",
       "      <td>0.284080</td>\n",
       "      <td>0.175425</td>\n",
       "      <td>0.136914</td>\n",
       "      <td>0.359222</td>\n",
       "      <td>0.470505</td>\n",
       "      <td>0.569552</td>\n",
       "      <td>0.476387</td>\n",
       "      <td>0.419598</td>\n",
       "      <td>0.466336</td>\n",
       "      <td>0.282844</td>\n",
       "      <td>0.315301</td>\n",
       "      <td>0.386399</td>\n",
       "      <td>0.457496</td>\n",
       "      <td>0.282844</td>\n",
       "      <td>0.265842</td>\n",
       "      <td>0.212056</td>\n",
       "      <td>0.135240</td>\n",
       "      <td>0.108192</td>\n",
       "      <td>0.271767</td>\n",
       "      <td>0.353297</td>\n",
       "      <td>0.446548</td>\n",
       "      <td>0.367233</td>\n",
       "      <td>0.320502</td>\n",
       "      <td>0.362774</td>\n",
       "      <td>0.367233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.660900</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.533230</td>\n",
       "      <td>0.579598</td>\n",
       "      <td>0.659969</td>\n",
       "      <td>0.751159</td>\n",
       "      <td>0.533230</td>\n",
       "      <td>0.499742</td>\n",
       "      <td>0.379907</td>\n",
       "      <td>0.225348</td>\n",
       "      <td>0.197063</td>\n",
       "      <td>0.502318</td>\n",
       "      <td>0.621329</td>\n",
       "      <td>0.730938</td>\n",
       "      <td>0.636730</td>\n",
       "      <td>0.580816</td>\n",
       "      <td>0.620899</td>\n",
       "      <td>0.530139</td>\n",
       "      <td>0.574961</td>\n",
       "      <td>0.650696</td>\n",
       "      <td>0.726430</td>\n",
       "      <td>0.530139</td>\n",
       "      <td>0.492530</td>\n",
       "      <td>0.372798</td>\n",
       "      <td>0.219165</td>\n",
       "      <td>0.198480</td>\n",
       "      <td>0.499614</td>\n",
       "      <td>0.609480</td>\n",
       "      <td>0.712004</td>\n",
       "      <td>0.626613</td>\n",
       "      <td>0.574242</td>\n",
       "      <td>0.614476</td>\n",
       "      <td>0.506955</td>\n",
       "      <td>0.550232</td>\n",
       "      <td>0.633694</td>\n",
       "      <td>0.706337</td>\n",
       "      <td>0.506955</td>\n",
       "      <td>0.470891</td>\n",
       "      <td>0.358578</td>\n",
       "      <td>0.214529</td>\n",
       "      <td>0.189979</td>\n",
       "      <td>0.478104</td>\n",
       "      <td>0.585394</td>\n",
       "      <td>0.693328</td>\n",
       "      <td>0.605691</td>\n",
       "      <td>0.551000</td>\n",
       "      <td>0.591829</td>\n",
       "      <td>0.428130</td>\n",
       "      <td>0.474498</td>\n",
       "      <td>0.561051</td>\n",
       "      <td>0.633694</td>\n",
       "      <td>0.428130</td>\n",
       "      <td>0.400309</td>\n",
       "      <td>0.314065</td>\n",
       "      <td>0.190881</td>\n",
       "      <td>0.161386</td>\n",
       "      <td>0.405719</td>\n",
       "      <td>0.514683</td>\n",
       "      <td>0.613859</td>\n",
       "      <td>0.528075</td>\n",
       "      <td>0.474082</td>\n",
       "      <td>0.519064</td>\n",
       "      <td>0.336940</td>\n",
       "      <td>0.370943</td>\n",
       "      <td>0.435858</td>\n",
       "      <td>0.513138</td>\n",
       "      <td>0.336940</td>\n",
       "      <td>0.314271</td>\n",
       "      <td>0.243277</td>\n",
       "      <td>0.150232</td>\n",
       "      <td>0.129315</td>\n",
       "      <td>0.322257</td>\n",
       "      <td>0.404946</td>\n",
       "      <td>0.496780</td>\n",
       "      <td>0.420035</td>\n",
       "      <td>0.375194</td>\n",
       "      <td>0.416844</td>\n",
       "      <td>0.420035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.826800</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.539413</td>\n",
       "      <td>0.585781</td>\n",
       "      <td>0.667697</td>\n",
       "      <td>0.751159</td>\n",
       "      <td>0.539413</td>\n",
       "      <td>0.503864</td>\n",
       "      <td>0.384235</td>\n",
       "      <td>0.226430</td>\n",
       "      <td>0.199897</td>\n",
       "      <td>0.505925</td>\n",
       "      <td>0.627254</td>\n",
       "      <td>0.734029</td>\n",
       "      <td>0.641860</td>\n",
       "      <td>0.586375</td>\n",
       "      <td>0.626893</td>\n",
       "      <td>0.536321</td>\n",
       "      <td>0.579598</td>\n",
       "      <td>0.661515</td>\n",
       "      <td>0.726430</td>\n",
       "      <td>0.536321</td>\n",
       "      <td>0.498712</td>\n",
       "      <td>0.380216</td>\n",
       "      <td>0.220093</td>\n",
       "      <td>0.199897</td>\n",
       "      <td>0.503478</td>\n",
       "      <td>0.621458</td>\n",
       "      <td>0.714967</td>\n",
       "      <td>0.631698</td>\n",
       "      <td>0.580273</td>\n",
       "      <td>0.620564</td>\n",
       "      <td>0.505410</td>\n",
       "      <td>0.557960</td>\n",
       "      <td>0.639876</td>\n",
       "      <td>0.704791</td>\n",
       "      <td>0.505410</td>\n",
       "      <td>0.475013</td>\n",
       "      <td>0.362287</td>\n",
       "      <td>0.214992</td>\n",
       "      <td>0.189722</td>\n",
       "      <td>0.482870</td>\n",
       "      <td>0.591061</td>\n",
       "      <td>0.696033</td>\n",
       "      <td>0.608507</td>\n",
       "      <td>0.552717</td>\n",
       "      <td>0.595465</td>\n",
       "      <td>0.443586</td>\n",
       "      <td>0.493045</td>\n",
       "      <td>0.578053</td>\n",
       "      <td>0.650696</td>\n",
       "      <td>0.443586</td>\n",
       "      <td>0.414735</td>\n",
       "      <td>0.325502</td>\n",
       "      <td>0.196291</td>\n",
       "      <td>0.167053</td>\n",
       "      <td>0.420659</td>\n",
       "      <td>0.532200</td>\n",
       "      <td>0.632277</td>\n",
       "      <td>0.545431</td>\n",
       "      <td>0.490539</td>\n",
       "      <td>0.534531</td>\n",
       "      <td>0.341577</td>\n",
       "      <td>0.370943</td>\n",
       "      <td>0.440495</td>\n",
       "      <td>0.511592</td>\n",
       "      <td>0.341577</td>\n",
       "      <td>0.315301</td>\n",
       "      <td>0.242968</td>\n",
       "      <td>0.151777</td>\n",
       "      <td>0.132406</td>\n",
       "      <td>0.324446</td>\n",
       "      <td>0.403400</td>\n",
       "      <td>0.497424</td>\n",
       "      <td>0.423429</td>\n",
       "      <td>0.378466</td>\n",
       "      <td>0.422078</td>\n",
       "      <td>0.423429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.648400</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.540958</td>\n",
       "      <td>0.585781</td>\n",
       "      <td>0.667697</td>\n",
       "      <td>0.752705</td>\n",
       "      <td>0.540958</td>\n",
       "      <td>0.504894</td>\n",
       "      <td>0.384544</td>\n",
       "      <td>0.226893</td>\n",
       "      <td>0.200283</td>\n",
       "      <td>0.506698</td>\n",
       "      <td>0.628156</td>\n",
       "      <td>0.735317</td>\n",
       "      <td>0.643090</td>\n",
       "      <td>0.587675</td>\n",
       "      <td>0.627867</td>\n",
       "      <td>0.534776</td>\n",
       "      <td>0.573416</td>\n",
       "      <td>0.659969</td>\n",
       "      <td>0.727975</td>\n",
       "      <td>0.534776</td>\n",
       "      <td>0.494590</td>\n",
       "      <td>0.378362</td>\n",
       "      <td>0.220402</td>\n",
       "      <td>0.199639</td>\n",
       "      <td>0.499742</td>\n",
       "      <td>0.619011</td>\n",
       "      <td>0.718058</td>\n",
       "      <td>0.631477</td>\n",
       "      <td>0.578590</td>\n",
       "      <td>0.618955</td>\n",
       "      <td>0.500773</td>\n",
       "      <td>0.557960</td>\n",
       "      <td>0.644513</td>\n",
       "      <td>0.704791</td>\n",
       "      <td>0.500773</td>\n",
       "      <td>0.471922</td>\n",
       "      <td>0.363833</td>\n",
       "      <td>0.214992</td>\n",
       "      <td>0.188305</td>\n",
       "      <td>0.479907</td>\n",
       "      <td>0.592993</td>\n",
       "      <td>0.696033</td>\n",
       "      <td>0.607305</td>\n",
       "      <td>0.550150</td>\n",
       "      <td>0.593768</td>\n",
       "      <td>0.440495</td>\n",
       "      <td>0.485317</td>\n",
       "      <td>0.581144</td>\n",
       "      <td>0.652241</td>\n",
       "      <td>0.440495</td>\n",
       "      <td>0.410098</td>\n",
       "      <td>0.323648</td>\n",
       "      <td>0.196291</td>\n",
       "      <td>0.166023</td>\n",
       "      <td>0.416151</td>\n",
       "      <td>0.530526</td>\n",
       "      <td>0.633694</td>\n",
       "      <td>0.544116</td>\n",
       "      <td>0.487990</td>\n",
       "      <td>0.532014</td>\n",
       "      <td>0.340031</td>\n",
       "      <td>0.375580</td>\n",
       "      <td>0.446677</td>\n",
       "      <td>0.511592</td>\n",
       "      <td>0.340031</td>\n",
       "      <td>0.316332</td>\n",
       "      <td>0.246059</td>\n",
       "      <td>0.152396</td>\n",
       "      <td>0.132148</td>\n",
       "      <td>0.326121</td>\n",
       "      <td>0.408423</td>\n",
       "      <td>0.498583</td>\n",
       "      <td>0.424785</td>\n",
       "      <td>0.378844</td>\n",
       "      <td>0.423376</td>\n",
       "      <td>0.424785</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Start training\n",
    "trainer.train()\n",
    "\n",
    "# Save the best model based on our eval_dim_128_cosine_ndcg@10 criteria\n",
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ac9d10f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model.safetensors: 100%|██████████| 596M/596M [02:17<00:00, 4.34MB/s]   \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://huggingface.co/Sri1999/modernbert-embed-base-legal-matryoshka-2/commit/15ef4243b9bfaac9905d54b4468de217bc1c3fe2'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.model.push_to_hub(\"modernbert-embed-base-legal-matryoshka-2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ca290e5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine Tuned Model Evaluation Results\n",
      "-------------------------------------------------------------------------------------\n",
      "Metric                  768d         512d         256d         128d          64d\n",
      "-------------------------------------------------------------------------------------\n",
      "==ndcg@10==            0.6418       0.6292       0.6080       0.5446       0.4246 \n",
      "mrr@10                 0.5866       0.5779       0.5501       0.4886       0.3791 \n",
      "map@100                0.6274       0.6184       0.5935       0.5327       0.4229 \n",
      "accuracy@1             0.5394       0.5348       0.5008       0.4420       0.3416 \n",
      "accuracy@3             0.5873       0.5765       0.5564       0.4869       0.3740 \n",
      "accuracy@5             0.6708       0.6569       0.6461       0.5750       0.4436 \n",
      "accuracy@10            0.7496       0.7233       0.7063       0.6507       0.5116 \n",
      "precision@1            0.5394       0.5348       0.5008       0.4420       0.3416 \n",
      "precision@3            0.5044       0.4961       0.4719       0.4111       0.3163 \n",
      "precision@5            0.3855       0.3777       0.3638       0.3227       0.2445 \n",
      "precision@10           0.2261       0.2193       0.2159       0.1966       0.1524 \n",
      "recall@1               0.1999       0.1993       0.1879       0.1668       0.1325 \n",
      "recall@3               0.5064       0.5009       0.4793       0.4173       0.3256 \n",
      "recall@5               0.6296       0.6177       0.5927       0.5267       0.4044 \n",
      "recall@10              0.7330       0.7124       0.6984       0.6334       0.4982 \n",
      "-------------------------------------------------------------------------------------\n",
      "seq_score: 0.424559\n"
     ]
    }
   ],
   "source": [
    "fine_tuned_model = SentenceTransformer(\n",
    "    args.output_dir, device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "ft_results = evaluator(fine_tuned_model)\n",
    "\n",
    "# Print header\n",
    "print(\"Fine Tuned Model Evaluation Results\")\n",
    "print(\"-\" * 85)\n",
    "print(f\"{'Metric':15} {'768d':>12} {'512d':>12} {'256d':>12} {'128d':>12} {'64d':>12}\")\n",
    "print(\"-\" * 85)\n",
    "\n",
    "# List of metrics to display\n",
    "metrics = [\n",
    "    'ndcg@10',\n",
    "    'mrr@10',\n",
    "    'map@100',\n",
    "    'accuracy@1',\n",
    "    'accuracy@3',\n",
    "    'accuracy@5',\n",
    "    'accuracy@10',\n",
    "    'precision@1',\n",
    "    'precision@3',\n",
    "    'precision@5',\n",
    "    'precision@10',\n",
    "    'recall@1',\n",
    "    'recall@3',\n",
    "    'recall@5',\n",
    "    'recall@10'\n",
    "]\n",
    "\n",
    "# Print each metric\n",
    "for metric in metrics:\n",
    "    values = []\n",
    "    for dim in matryoshka_dimensions:\n",
    "        key = f\"dim_{dim}_cosine_{metric}\"\n",
    "        values.append(ft_results[key])\n",
    "\n",
    "    # Highlight NDCG@10\n",
    "    metric_name = f\"=={metric}==\" if metric == \"ndcg@10\" else metric\n",
    "    print(f\"{metric_name:15}\", end=\"  \")\n",
    "    for val in values:\n",
    "        print(f\"{val:12.4f}\", end=\" \")\n",
    "    print()\n",
    "\n",
    "# Print sequential score\n",
    "print(\"-\" * 85)\n",
    "print(f\"{'seq_score:'} {ft_results['sequential_score']:1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "00794dde",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Narwal\\fine_tuning_embedding_models\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\sriha\\.cache\\huggingface\\hub\\models--AdamLucek--ModernBERT-embed-base-legal-MRL. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Download from the 🤗 Hub\n",
    "model = SentenceTransformer(\"AdamLucek/ModernBERT-embed-base-legal-MRL\", truncate_dim=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1fdec3a7",
   "metadata": {},
   "outputs": [
    {
     "ename": "BackendCompilerFailed",
     "evalue": "backend='inductor' raised:\nRuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton\n\nSet TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n\n\nYou can suppress this exception and fall back to eager by setting:\n    import torch._dynamo\n    torch._dynamo.config.suppress_errors = True\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Narwal\\fine_tuning_embedding_models\\.venv\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py:1446\u001b[39m, in \u001b[36mOutputGraph._call_user_compiler\u001b[39m\u001b[34m(self, gm)\u001b[39m\n\u001b[32m   1445\u001b[39m     compiler_fn = WrapperBackend(compiler_fn)\n\u001b[32m-> \u001b[39m\u001b[32m1446\u001b[39m compiled_fn = \u001b[43mcompiler_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1447\u001b[39m _step_logger()(logging.INFO, \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mdone compiler function \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Narwal\\fine_tuning_embedding_models\\.venv\\Lib\\site-packages\\torch\\_dynamo\\repro\\after_dynamo.py:129\u001b[39m, in \u001b[36mWrapBackendDebug.__call__\u001b[39m\u001b[34m(self, gm, example_inputs, **kwargs)\u001b[39m\n\u001b[32m    128\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m129\u001b[39m     compiled_gm = \u001b[43mcompiler_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    131\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m compiled_gm\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Narwal\\fine_tuning_embedding_models\\.venv\\Lib\\site-packages\\torch\\__init__.py:2234\u001b[39m, in \u001b[36m_TorchCompileInductorWrapper.__call__\u001b[39m\u001b[34m(self, model_, inputs_)\u001b[39m\n\u001b[32m   2232\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_inductor\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcompile_fx\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m compile_fx\n\u001b[32m-> \u001b[39m\u001b[32m2234\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcompile_fx\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig_patches\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Narwal\\fine_tuning_embedding_models\\.venv\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py:1521\u001b[39m, in \u001b[36mcompile_fx\u001b[39m\u001b[34m(model_, example_inputs_, inner_compile, config_patches, decompositions)\u001b[39m\n\u001b[32m   1516\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m V.set_fake_mode(fake_mode), torch._guards.tracing(\n\u001b[32m   1517\u001b[39m     tracing_context\n\u001b[32m   1518\u001b[39m ), compiled_autograd.disable(), functorch_config.patch(\n\u001b[32m   1519\u001b[39m     unlift_effect_tokens=\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m   1520\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1521\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43maot_autograd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1522\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfw_compiler\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfw_compiler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1523\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbw_compiler\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbw_compiler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1524\u001b[39m \u001b[43m        \u001b[49m\u001b[43minference_compiler\u001b[49m\u001b[43m=\u001b[49m\u001b[43minference_compiler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1525\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecompositions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecompositions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1526\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpartition_fn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpartition_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1527\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkeep_inference_input_mutations\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1528\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcudagraphs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcudagraphs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1529\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample_inputs_\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Narwal\\fine_tuning_embedding_models\\.venv\\Lib\\site-packages\\torch\\_dynamo\\backends\\common.py:72\u001b[39m, in \u001b[36mAotAutograd.__call__\u001b[39m\u001b[34m(self, gm, example_inputs, **kwargs)\u001b[39m\n\u001b[32m     71\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m enable_aot_logging(), patch_config:\n\u001b[32m---> \u001b[39m\u001b[32m72\u001b[39m     cg = \u001b[43maot_module_simplified\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     73\u001b[39m     counters[\u001b[33m\"\u001b[39m\u001b[33maot_autograd\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mok\u001b[39m\u001b[33m\"\u001b[39m] += \u001b[32m1\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Narwal\\fine_tuning_embedding_models\\.venv\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py:1071\u001b[39m, in \u001b[36maot_module_simplified\u001b[39m\u001b[34m(mod, args, fw_compiler, bw_compiler, partition_fn, decompositions, keep_inference_input_mutations, inference_compiler, cudagraphs)\u001b[39m\n\u001b[32m   1070\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1071\u001b[39m     compiled_fn = \u001b[43mdispatch_and_compile\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1073\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mod, torch._dynamo.utils.GmWrapper):\n\u001b[32m   1074\u001b[39m     \u001b[38;5;66;03m# This function is called by the flatten_graph_inputs wrapper, which boxes\u001b[39;00m\n\u001b[32m   1075\u001b[39m     \u001b[38;5;66;03m# the inputs so that they can be freed before the end of this scope.\u001b[39;00m\n\u001b[32m   1076\u001b[39m     \u001b[38;5;66;03m# For overhead reasons, this is not the default wrapper, see comment:\u001b[39;00m\n\u001b[32m   1077\u001b[39m     \u001b[38;5;66;03m# https://github.com/pytorch/pytorch/pull/122535/files#r1560096481\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Narwal\\fine_tuning_embedding_models\\.venv\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py:1056\u001b[39m, in \u001b[36maot_module_simplified.<locals>.dispatch_and_compile\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m   1055\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m compiled_autograd.disable():\n\u001b[32m-> \u001b[39m\u001b[32m1056\u001b[39m     compiled_fn, _ = \u001b[43mcreate_aot_dispatcher_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1057\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunctional_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1058\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfake_flat_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1059\u001b[39m \u001b[43m        \u001b[49m\u001b[43maot_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1060\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfake_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1061\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshape_env\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1062\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1063\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m compiled_fn\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Narwal\\fine_tuning_embedding_models\\.venv\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py:522\u001b[39m, in \u001b[36mcreate_aot_dispatcher_function\u001b[39m\u001b[34m(flat_fn, fake_flat_args, aot_config, fake_mode, shape_env)\u001b[39m\n\u001b[32m    521\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m dynamo_timed(\u001b[33m\"\u001b[39m\u001b[33mcreate_aot_dispatcher_function\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m522\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_create_aot_dispatcher_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    523\u001b[39m \u001b[43m        \u001b[49m\u001b[43mflat_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfake_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maot_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfake_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape_env\u001b[49m\n\u001b[32m    524\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Narwal\\fine_tuning_embedding_models\\.venv\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py:759\u001b[39m, in \u001b[36m_create_aot_dispatcher_function\u001b[39m\u001b[34m(flat_fn, fake_flat_args, aot_config, fake_mode, shape_env)\u001b[39m\n\u001b[32m    757\u001b[39m compiler_fn = choose_dispatcher(needs_autograd, aot_config)\n\u001b[32m--> \u001b[39m\u001b[32m759\u001b[39m compiled_fn, fw_metadata = \u001b[43mcompiler_fn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    760\u001b[39m \u001b[43m    \u001b[49m\u001b[43mflat_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    761\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_dup_fake_script_obj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfake_flat_args\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    762\u001b[39m \u001b[43m    \u001b[49m\u001b[43maot_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    763\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfw_metadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfw_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    764\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    765\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m compiled_fn, fw_metadata\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Narwal\\fine_tuning_embedding_models\\.venv\\Lib\\site-packages\\torch\\_functorch\\_aot_autograd\\jit_compile_runtime_wrappers.py:179\u001b[39m, in \u001b[36maot_dispatch_base\u001b[39m\u001b[34m(flat_fn, flat_args, aot_config, fw_metadata)\u001b[39m\n\u001b[32m    178\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m TracingContext.report_output_strides() \u001b[38;5;28;01mas\u001b[39;00m fwd_output_strides:\n\u001b[32m--> \u001b[39m\u001b[32m179\u001b[39m     compiled_fw = \u001b[43mcompiler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfw_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mupdated_flat_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    181\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m fakified_out_wrapper.needs_post_compile:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Narwal\\fine_tuning_embedding_models\\.venv\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py:1350\u001b[39m, in \u001b[36mcompile_fx.<locals>.fw_compiler_base\u001b[39m\u001b[34m(model, example_inputs, is_inference)\u001b[39m\n\u001b[32m   1349\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m dynamo_utils.dynamo_timed(\u001b[33m\"\u001b[39m\u001b[33mcompile_fx.<locals>.fw_compiler_base\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1350\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_fw_compiler_base\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_inference\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Narwal\\fine_tuning_embedding_models\\.venv\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py:1421\u001b[39m, in \u001b[36mcompile_fx.<locals>._fw_compiler_base\u001b[39m\u001b[34m(model, example_inputs, is_inference)\u001b[39m\n\u001b[32m   1413\u001b[39m     user_visible_outputs = \u001b[38;5;28mdict\u001b[39m.fromkeys(\n\u001b[32m   1414\u001b[39m         n.name\n\u001b[32m   1415\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m model_outputs[\n\u001b[32m   (...)\u001b[39m\u001b[32m   1418\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(n, torch.fx.Node)\n\u001b[32m   1419\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1421\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_compile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1422\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1423\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1424\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstatic_input_idxs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_static_input_idxs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfixed\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1425\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcudagraphs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcudagraphs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1426\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgraph_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgraph_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1427\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_inference\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_inference\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1428\u001b[39m \u001b[43m    \u001b[49m\u001b[43mboxed_forward_device_index\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforward_device\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1429\u001b[39m \u001b[43m    \u001b[49m\u001b[43muser_visible_outputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43muser_visible_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1430\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Narwal\\fine_tuning_embedding_models\\.venv\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py:475\u001b[39m, in \u001b[36mcompile_fx_inner\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    473\u001b[39m stack.enter_context(DebugContext())\n\u001b[32m--> \u001b[39m\u001b[32m475\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrap_compiler_debug\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_compile_fx_inner\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompiler_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minductor\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    476\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    477\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Narwal\\fine_tuning_embedding_models\\.venv\\Lib\\site-packages\\torch\\_dynamo\\repro\\after_aot.py:85\u001b[39m, in \u001b[36mwrap_compiler_debug.<locals>.debug_wrapper\u001b[39m\u001b[34m(gm, example_inputs, **kwargs)\u001b[39m\n\u001b[32m     82\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     83\u001b[39m     \u001b[38;5;66;03m# Call the compiler_fn - which is either aot_autograd or inductor\u001b[39;00m\n\u001b[32m     84\u001b[39m     \u001b[38;5;66;03m# with fake inputs\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m85\u001b[39m     inner_compiled_fn = \u001b[43mcompiler_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     86\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     87\u001b[39m     \u001b[38;5;66;03m# TODO: Failures here are troublesome because no real inputs,\u001b[39;00m\n\u001b[32m     88\u001b[39m     \u001b[38;5;66;03m# need a different serialization strategy\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Narwal\\fine_tuning_embedding_models\\.venv\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py:661\u001b[39m, in \u001b[36m_compile_fx_inner\u001b[39m\u001b[34m(gm, example_inputs, cudagraphs, static_input_idxs, is_backward, graph_id, cpp_wrapper, aot_mode, is_inference, boxed_forward_device_index, user_visible_outputs, layout_opt, extern_node_serializer)\u001b[39m\n\u001b[32m    659\u001b[39m             \u001b[38;5;28minput\u001b[39m._is_inductor_static = \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m661\u001b[39m     compiled_graph = \u001b[43mFxGraphCache\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    662\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcodegen_and_compile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    663\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    664\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    665\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgraph_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    666\u001b[39m \u001b[43m        \u001b[49m\u001b[43minputs_to_check\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    667\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlocal\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfx_graph_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    668\u001b[39m \u001b[43m        \u001b[49m\u001b[43mremote\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfx_graph_remote_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    669\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    670\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Narwal\\fine_tuning_embedding_models\\.venv\\Lib\\site-packages\\torch\\_inductor\\codecache.py:1334\u001b[39m, in \u001b[36mFxGraphCache.load\u001b[39m\u001b[34m(compile_fx_fn, gm, example_inputs, fx_kwargs, inputs_to_check, local, remote)\u001b[39m\n\u001b[32m   1333\u001b[39m cache_event_time = start_time\n\u001b[32m-> \u001b[39m\u001b[32m1334\u001b[39m compiled_graph = \u001b[43mcompile_fx_fn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1335\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs_to_check\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfx_kwargs\u001b[49m\n\u001b[32m   1336\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1337\u001b[39m compiled_graph._time_taken_ns = time_ns() - start_time\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Narwal\\fine_tuning_embedding_models\\.venv\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py:570\u001b[39m, in \u001b[36m_compile_fx_inner.<locals>.codegen_and_compile\u001b[39m\u001b[34m(gm, example_inputs, inputs_to_check, fx_kwargs)\u001b[39m\n\u001b[32m    566\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    567\u001b[39m \u001b[33;03mThis function calls fx_codegen_and_compile and also adds some extra metadata to the resulting\u001b[39;00m\n\u001b[32m    568\u001b[39m \u001b[33;03mcompiled fx graph. The metadata is saved to FXGraphCache.\u001b[39;00m\n\u001b[32m    569\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m570\u001b[39m compiled_graph = \u001b[43mfx_codegen_and_compile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfx_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    571\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(compiled_graph, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    572\u001b[39m     \u001b[38;5;66;03m# We only return a string in aot mode, in which case we don't\u001b[39;00m\n\u001b[32m    573\u001b[39m     \u001b[38;5;66;03m# need to do any post-compilation steps: we just return the string,\u001b[39;00m\n\u001b[32m    574\u001b[39m     \u001b[38;5;66;03m# which is the filename of the compiled code.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Narwal\\fine_tuning_embedding_models\\.venv\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py:878\u001b[39m, in \u001b[36mfx_codegen_and_compile\u001b[39m\u001b[34m(gm, example_inputs, cudagraphs, static_input_idxs, is_backward, graph_id, cpp_wrapper, aot_mode, is_inference, user_visible_outputs, layout_opt, extern_node_serializer)\u001b[39m\n\u001b[32m    877\u001b[39m _check_triton_bf16_support(graph)\n\u001b[32m--> \u001b[39m\u001b[32m878\u001b[39m compiled_fn = \u001b[43mgraph\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompile_to_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    879\u001b[39m num_bytes, nodes_num_elem, node_runtimes = graph.count_bytes()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Narwal\\fine_tuning_embedding_models\\.venv\\Lib\\site-packages\\torch\\_inductor\\graph.py:1913\u001b[39m, in \u001b[36mGraphLowering.compile_to_fn\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1912\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1913\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompile_to_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m.call\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Narwal\\fine_tuning_embedding_models\\.venv\\Lib\\site-packages\\torch\\_inductor\\graph.py:1839\u001b[39m, in \u001b[36mGraphLowering.compile_to_module\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1836\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m dynamo_timed(\n\u001b[32m   1837\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mGraphLowering.compile_to_module\u001b[39m\u001b[33m\"\u001b[39m, phase_name=\u001b[33m\"\u001b[39m\u001b[33mcode_gen\u001b[39m\u001b[33m\"\u001b[39m, fwd_only=\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m   1838\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1839\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_compile_to_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Narwal\\fine_tuning_embedding_models\\.venv\\Lib\\site-packages\\torch\\_inductor\\graph.py:1845\u001b[39m, in \u001b[36mGraphLowering._compile_to_module\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1842\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcodecache\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PyCodeCache\n\u001b[32m   1844\u001b[39m code, linemap = (\n\u001b[32m-> \u001b[39m\u001b[32m1845\u001b[39m     \u001b[38;5;28mself\u001b[39m.codegen_with_cpp_wrapper() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.cpp_wrapper \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcodegen\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1846\u001b[39m )\n\u001b[32m   1848\u001b[39m GraphLowering.save_output_code(code)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Narwal\\fine_tuning_embedding_models\\.venv\\Lib\\site-packages\\torch\\_inductor\\graph.py:1780\u001b[39m, in \u001b[36mGraphLowering.codegen\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1778\u001b[39m \u001b[38;5;28mself\u001b[39m.init_wrapper_code()\n\u001b[32m-> \u001b[39m\u001b[32m1780\u001b[39m \u001b[38;5;28mself\u001b[39m.scheduler = \u001b[43mScheduler\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moperations\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1781\u001b[39m V.debug.draw_orig_fx_graph(\u001b[38;5;28mself\u001b[39m.orig_gm, \u001b[38;5;28mself\u001b[39m.scheduler.nodes)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Narwal\\fine_tuning_embedding_models\\.venv\\Lib\\site-packages\\torch\\_inductor\\scheduler.py:1731\u001b[39m, in \u001b[36mScheduler.__init__\u001b[39m\u001b[34m(self, nodes)\u001b[39m\n\u001b[32m   1730\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m dynamo_timed(\u001b[33m\"\u001b[39m\u001b[33mScheduler.__init__\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1731\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnodes\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Narwal\\fine_tuning_embedding_models\\.venv\\Lib\\site-packages\\torch\\_inductor\\scheduler.py:1749\u001b[39m, in \u001b[36mScheduler._init\u001b[39m\u001b[34m(self, nodes)\u001b[39m\n\u001b[32m   1741\u001b[39m \u001b[38;5;28mself\u001b[39m.available_buffer_names = OrderedSet(\n\u001b[32m   1742\u001b[39m     [\n\u001b[32m   1743\u001b[39m         *V.graph.graph_inputs.keys(),\n\u001b[32m   (...)\u001b[39m\u001b[32m   1746\u001b[39m     ]\n\u001b[32m   1747\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1749\u001b[39m \u001b[38;5;28mself\u001b[39m.nodes = \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcreate_scheduler_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mnodes\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28mself\u001b[39m.update_zero_dim_cpu_tensor()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Narwal\\fine_tuning_embedding_models\\.venv\\Lib\\site-packages\\torch\\_inductor\\scheduler.py:1749\u001b[39m, in \u001b[36m<listcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m   1741\u001b[39m \u001b[38;5;28mself\u001b[39m.available_buffer_names = OrderedSet(\n\u001b[32m   1742\u001b[39m     [\n\u001b[32m   1743\u001b[39m         *V.graph.graph_inputs.keys(),\n\u001b[32m   (...)\u001b[39m\u001b[32m   1746\u001b[39m     ]\n\u001b[32m   1747\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1749\u001b[39m \u001b[38;5;28mself\u001b[39m.nodes = [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcreate_scheduler_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m nodes]\n\u001b[32m   1750\u001b[39m \u001b[38;5;28mself\u001b[39m.update_zero_dim_cpu_tensor()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Narwal\\fine_tuning_embedding_models\\.venv\\Lib\\site-packages\\torch\\_inductor\\scheduler.py:1856\u001b[39m, in \u001b[36mScheduler.create_scheduler_node\u001b[39m\u001b[34m(self, node)\u001b[39m\n\u001b[32m   1855\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(node, (ir.ComputedBuffer, ir.TemplateBuffer)):\n\u001b[32m-> \u001b[39m\u001b[32m1856\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSchedulerNode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1857\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(node, ir.ExternKernel):\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Narwal\\fine_tuning_embedding_models\\.venv\\Lib\\site-packages\\torch\\_inductor\\scheduler.py:833\u001b[39m, in \u001b[36mSchedulerNode.__init__\u001b[39m\u001b[34m(self, scheduler, node)\u001b[39m\n\u001b[32m    832\u001b[39m \u001b[38;5;28mself\u001b[39m._init_from_node(node)\n\u001b[32m--> \u001b[39m\u001b[32m833\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_compute_attrs\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Narwal\\fine_tuning_embedding_models\\.venv\\Lib\\site-packages\\torch\\_inductor\\scheduler.py:846\u001b[39m, in \u001b[36mSchedulerNode._compute_attrs\u001b[39m\u001b[34m(self, extra_indexing_constraints, recompute_sizes_body_func)\u001b[39m\n\u001b[32m    841\u001b[39m \u001b[38;5;28mself\u001b[39m._sizes, \u001b[38;5;28mself\u001b[39m._body = \u001b[38;5;28mself\u001b[39m.node.simplify_and_reorder(\n\u001b[32m    842\u001b[39m     extra_indexing_constraints=extra_indexing_constraints,\n\u001b[32m    843\u001b[39m     recompute_sizes_body_func=recompute_sizes_body_func,\n\u001b[32m    844\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m846\u001b[39m group_fn = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_backend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m.group_fn\n\u001b[32m    847\u001b[39m \u001b[38;5;28mself\u001b[39m.group = (\u001b[38;5;28mself\u001b[39m.node.get_device(), group_fn(\u001b[38;5;28mself\u001b[39m._sizes))\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Narwal\\fine_tuning_embedding_models\\.venv\\Lib\\site-packages\\torch\\_inductor\\scheduler.py:3360\u001b[39m, in \u001b[36mScheduler.get_backend\u001b[39m\u001b[34m(self, device)\u001b[39m\n\u001b[32m   3359\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.backends:\n\u001b[32m-> \u001b[39m\u001b[32m3360\u001b[39m     \u001b[38;5;28mself\u001b[39m.backends[device] = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcreate_backend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3361\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.backends[device]\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Narwal\\fine_tuning_embedding_models\\.venv\\Lib\\site-packages\\torch\\_inductor\\scheduler.py:3352\u001b[39m, in \u001b[36mScheduler.create_backend\u001b[39m\u001b[34m(self, device)\u001b[39m\n\u001b[32m   3351\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m is_gpu(device.type):\n\u001b[32m-> \u001b[39m\u001b[32m3352\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   3353\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mCannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton\u001b[39m\u001b[33m\"\u001b[39m  \u001b[38;5;66;03m# noqa: B950\u001b[39;00m\n\u001b[32m   3354\u001b[39m         )\n\u001b[32m   3356\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m device_scheduling(\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[31mRuntimeError\u001b[39m: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mBackendCompilerFailed\u001b[39m                     Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      1\u001b[39m sentences = [\n\u001b[32m      2\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mWhich organization is Carmody Gaba Daman associated with?\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m      3\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mAssistant General Counsel, U.S. General Services Administration, Washington, D.C.; Carmody Gaba Daman, Assistant General Counsel, U.S. General Services Administration, Washington, D.C.; Michael Blumenthal, Trial Attorney, U.S. Small Business Administration, Office of General Counsel, Washington, D.C. MEMORANDUM AND ORDER\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;66;03m# Corresponding Positive\u001b[39;00m\n\u001b[32m      4\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mcertain Solicitation requirements violate federal procurement statutes and agency regulations governing procurements involving small business offerors. See generally SHS MJAR at 14; VCH MJAR at 14. Having considered the parties’ arguments, applicable law, and the Administrative Record, this Court GRANTS in part and DENIES in part Plaintiffs’ Motions for Judgment on the\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;66;03m# Random Excerpt\u001b[39;00m\n\u001b[32m      5\u001b[39m ]\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m embeddings = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43msentences\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(embeddings.shape)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Narwal\\fine_tuning_embedding_models\\.venv\\Lib\\site-packages\\torch\\utils\\_contextlib.py:116\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Narwal\\fine_tuning_embedding_models\\.venv\\Lib\\site-packages\\sentence_transformers\\SentenceTransformer.py:1094\u001b[39m, in \u001b[36mSentenceTransformer.encode\u001b[39m\u001b[34m(self, sentences, prompt_name, prompt, batch_size, show_progress_bar, output_value, precision, convert_to_numpy, convert_to_tensor, device, normalize_embeddings, truncate_dim, pool, chunk_size, **kwargs)\u001b[39m\n\u001b[32m   1091\u001b[39m features.update(extra_features)\n\u001b[32m   1093\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m-> \u001b[39m\u001b[32m1094\u001b[39m     out_features = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1095\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.device.type == \u001b[33m\"\u001b[39m\u001b[33mhpu\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   1096\u001b[39m         out_features = copy.deepcopy(out_features)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Narwal\\fine_tuning_embedding_models\\.venv\\Lib\\site-packages\\sentence_transformers\\SentenceTransformer.py:1175\u001b[39m, in \u001b[36mSentenceTransformer.forward\u001b[39m\u001b[34m(self, input, **kwargs)\u001b[39m\n\u001b[32m   1169\u001b[39m             module_kwarg_keys = \u001b[38;5;28mself\u001b[39m.module_kwargs.get(module_name, [])\n\u001b[32m   1170\u001b[39m         module_kwargs = {\n\u001b[32m   1171\u001b[39m             key: value\n\u001b[32m   1172\u001b[39m             \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m kwargs.items()\n\u001b[32m   1173\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m module_kwarg_keys \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;28mhasattr\u001b[39m(module, \u001b[33m\"\u001b[39m\u001b[33mforward_kwargs\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m module.forward_kwargs)\n\u001b[32m   1174\u001b[39m         }\n\u001b[32m-> \u001b[39m\u001b[32m1175\u001b[39m     \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodule_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1176\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Narwal\\fine_tuning_embedding_models\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Narwal\\fine_tuning_embedding_models\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Narwal\\fine_tuning_embedding_models\\.venv\\Lib\\site-packages\\sentence_transformers\\models\\Transformer.py:262\u001b[39m, in \u001b[36mTransformer.forward\u001b[39m\u001b[34m(self, features, **kwargs)\u001b[39m\n\u001b[32m    239\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    240\u001b[39m \u001b[33;03mForward pass through the transformer model.\u001b[39;00m\n\u001b[32m    241\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    258\u001b[39m \u001b[33;03m        - 'all_layer_embeddings': If the model outputs hidden states, contains embeddings from all layers\u001b[39;00m\n\u001b[32m    259\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    260\u001b[39m trans_features = {key: value \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m features.items() \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.model_forward_params}\n\u001b[32m--> \u001b[39m\u001b[32m262\u001b[39m outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mauto_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mtrans_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    263\u001b[39m token_embeddings = outputs[\u001b[32m0\u001b[39m]\n\u001b[32m    264\u001b[39m features[\u001b[33m\"\u001b[39m\u001b[33mtoken_embeddings\u001b[39m\u001b[33m\"\u001b[39m] = token_embeddings\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Narwal\\fine_tuning_embedding_models\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Narwal\\fine_tuning_embedding_models\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Narwal\\fine_tuning_embedding_models\\.venv\\Lib\\site-packages\\transformers\\models\\modernbert\\modeling_modernbert.py:863\u001b[39m, in \u001b[36mModernBertModel.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, sliding_window_mask, position_ids, inputs_embeds, indices, cu_seqlens, max_seqlen, batch_size, seq_len, output_attentions, output_hidden_states, return_dict)\u001b[39m\n\u001b[32m    857\u001b[39m         position_ids = torch.arange(seq_len, device=device).unsqueeze(\u001b[32m0\u001b[39m)\n\u001b[32m    859\u001b[39m     attention_mask, sliding_window_mask = \u001b[38;5;28mself\u001b[39m._update_attention_mask(\n\u001b[32m    860\u001b[39m         attention_mask, output_attentions=output_attentions\n\u001b[32m    861\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m863\u001b[39m hidden_states = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    865\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m encoder_layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.layers:\n\u001b[32m    866\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Narwal\\fine_tuning_embedding_models\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Narwal\\fine_tuning_embedding_models\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Narwal\\fine_tuning_embedding_models\\.venv\\Lib\\site-packages\\transformers\\models\\modernbert\\modeling_modernbert.py:218\u001b[39m, in \u001b[36mModernBertEmbeddings.forward\u001b[39m\u001b[34m(self, input_ids, inputs_embeds)\u001b[39m\n\u001b[32m    215\u001b[39m     hidden_states = \u001b[38;5;28mself\u001b[39m.drop(\u001b[38;5;28mself\u001b[39m.norm(inputs_embeds))\n\u001b[32m    216\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    217\u001b[39m     hidden_states = (\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompiled_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    219\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.config.reference_compile\n\u001b[32m    220\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.drop(\u001b[38;5;28mself\u001b[39m.norm(\u001b[38;5;28mself\u001b[39m.tok_embeddings(input_ids)))\n\u001b[32m    221\u001b[39m     )\n\u001b[32m    222\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m hidden_states\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Narwal\\fine_tuning_embedding_models\\.venv\\Lib\\site-packages\\torch\\_dynamo\\eval_frame.py:465\u001b[39m, in \u001b[36m_TorchDynamoContext.__call__.<locals>._fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    460\u001b[39m saved_dynamic_layer_stack_depth = (\n\u001b[32m    461\u001b[39m     torch._C._functorch.get_dynamic_layer_stack_depth()\n\u001b[32m    462\u001b[39m )\n\u001b[32m    464\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m465\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    466\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    467\u001b[39m     \u001b[38;5;66;03m# Restore the dynamic layer stack depth if necessary.\u001b[39;00m\n\u001b[32m    468\u001b[39m     torch._C._functorch.pop_dynamic_layer_stack_and_undo_to_depth(\n\u001b[32m    469\u001b[39m         saved_dynamic_layer_stack_depth\n\u001b[32m    470\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Narwal\\fine_tuning_embedding_models\\.venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1269\u001b[39m, in \u001b[36mCatchErrorsWrapper.__call__\u001b[39m\u001b[34m(self, frame, cache_entry, frame_state)\u001b[39m\n\u001b[32m   1263\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m hijacked_callback(\n\u001b[32m   1264\u001b[39m                 frame, cache_entry, \u001b[38;5;28mself\u001b[39m.hooks, frame_state\n\u001b[32m   1265\u001b[39m             )\n\u001b[32m   1267\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m compile_lock, _disable_current_modes():\n\u001b[32m   1268\u001b[39m     \u001b[38;5;66;03m# skip=1: skip this frame\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1269\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_torchdynamo_orig_callable\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1270\u001b[39m \u001b[43m        \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_entry\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\n\u001b[32m   1271\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Narwal\\fine_tuning_embedding_models\\.venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1064\u001b[39m, in \u001b[36mConvertFrame.__call__\u001b[39m\u001b[34m(self, frame, cache_entry, hooks, frame_state, skip)\u001b[39m\n\u001b[32m   1062\u001b[39m counters[\u001b[33m\"\u001b[39m\u001b[33mframes\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mtotal\u001b[39m\u001b[33m\"\u001b[39m] += \u001b[32m1\u001b[39m\n\u001b[32m   1063\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1064\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_inner_convert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1065\u001b[39m \u001b[43m        \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_entry\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskip\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\n\u001b[32m   1066\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1067\u001b[39m     counters[\u001b[33m\"\u001b[39m\u001b[33mframes\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mok\u001b[39m\u001b[33m\"\u001b[39m] += \u001b[32m1\u001b[39m\n\u001b[32m   1068\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Narwal\\fine_tuning_embedding_models\\.venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:526\u001b[39m, in \u001b[36mConvertFrameAssert.__call__\u001b[39m\u001b[34m(self, frame, cache_entry, hooks, frame_state, skip)\u001b[39m\n\u001b[32m    510\u001b[39m compile_id = CompileId(frame_id, frame_compile_id)\n\u001b[32m    512\u001b[39m signpost_event(\n\u001b[32m    513\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mdynamo\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    514\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m_convert_frame_assert._compile\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    523\u001b[39m     },\n\u001b[32m    524\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m526\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_compile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    527\u001b[39m \u001b[43m    \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mf_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    528\u001b[39m \u001b[43m    \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mf_globals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    529\u001b[39m \u001b[43m    \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mf_locals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    530\u001b[39m \u001b[43m    \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mf_builtins\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    531\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_torchdynamo_orig_callable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    532\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_one_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    533\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_export\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    534\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_export_constraints\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    535\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    536\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_entry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    537\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    538\u001b[39m \u001b[43m    \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    539\u001b[39m \u001b[43m    \u001b[49m\u001b[43mframe_state\u001b[49m\u001b[43m=\u001b[49m\u001b[43mframe_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    540\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompile_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompile_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    541\u001b[39m \u001b[43m    \u001b[49m\u001b[43mskip\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskip\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    542\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Narwal\\fine_tuning_embedding_models\\.venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:924\u001b[39m, in \u001b[36m_compile\u001b[39m\u001b[34m(code, globals, locals, builtins, compiler_fn, one_graph, export, export_constraints, hooks, cache_entry, cache_size, frame, frame_state, compile_id, skip)\u001b[39m\n\u001b[32m    922\u001b[39m guarded_code = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    923\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m924\u001b[39m     guarded_code = \u001b[43mcompile_inner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mone_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    925\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m guarded_code\n\u001b[32m    926\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Narwal\\fine_tuning_embedding_models\\.venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:666\u001b[39m, in \u001b[36m_compile.<locals>.compile_inner\u001b[39m\u001b[34m(code, one_graph, hooks, transform)\u001b[39m\n\u001b[32m    664\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m dynamo_timed(\u001b[33m\"\u001b[39m\u001b[33m_compile.compile_inner\u001b[39m\u001b[33m\"\u001b[39m, phase_name=\u001b[33m\"\u001b[39m\u001b[33mentire_frame_compile\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    665\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m CompileTimeInstructionCounter.record():\n\u001b[32m--> \u001b[39m\u001b[32m666\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_compile_inner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mone_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Narwal\\fine_tuning_embedding_models\\.venv\\Lib\\site-packages\\torch\\_utils_internal.py:87\u001b[39m, in \u001b[36mcompile_time_strobelight_meta.<locals>.compile_time_strobelight_meta_inner.<locals>.wrapper_function\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     84\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mskip\u001b[39m\u001b[33m\"\u001b[39m] = kwargs[\u001b[33m\"\u001b[39m\u001b[33mskip\u001b[39m\u001b[33m\"\u001b[39m] + \u001b[32m1\u001b[39m\n\u001b[32m     86\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m StrobelightCompileTimeProfiler.enabled:\n\u001b[32m---> \u001b[39m\u001b[32m87\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     89\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m StrobelightCompileTimeProfiler.profile_compile_time(\n\u001b[32m     90\u001b[39m     function, phase_name, *args, **kwargs\n\u001b[32m     91\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Narwal\\fine_tuning_embedding_models\\.venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:699\u001b[39m, in \u001b[36m_compile.<locals>._compile_inner\u001b[39m\u001b[34m(code, one_graph, hooks, transform)\u001b[39m\n\u001b[32m    697\u001b[39m CompileContext.get().attempt = attempt\n\u001b[32m    698\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m699\u001b[39m     out_code = \u001b[43mtransform_code_object\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    700\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    701\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m exc.RestartAnalysis \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Narwal\\fine_tuning_embedding_models\\.venv\\Lib\\site-packages\\torch\\_dynamo\\bytecode_transformation.py:1322\u001b[39m, in \u001b[36mtransform_code_object\u001b[39m\u001b[34m(code, transformations, safe)\u001b[39m\n\u001b[32m   1319\u001b[39m instructions = cleaned_instructions(code, safe)\n\u001b[32m   1320\u001b[39m propagate_line_nums(instructions)\n\u001b[32m-> \u001b[39m\u001b[32m1322\u001b[39m \u001b[43mtransformations\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstructions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode_options\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1323\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m clean_and_assemble_instructions(instructions, keys, code_options)[\u001b[32m1\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Narwal\\fine_tuning_embedding_models\\.venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:219\u001b[39m, in \u001b[36mpreserve_global_state.<locals>._fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    215\u001b[39m exit_stack.enter_context(\n\u001b[32m    216\u001b[39m     torch.fx._symbolic_trace._maybe_revert_all_patches()\n\u001b[32m    217\u001b[39m )\n\u001b[32m    218\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m219\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    220\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    221\u001b[39m     cleanup.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Narwal\\fine_tuning_embedding_models\\.venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:634\u001b[39m, in \u001b[36m_compile.<locals>.transform\u001b[39m\u001b[34m(instructions, code_options)\u001b[39m\n\u001b[32m    632\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    633\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m tracing(tracer.output.tracing_context), tracer.set_current_tx():\n\u001b[32m--> \u001b[39m\u001b[32m634\u001b[39m         \u001b[43mtracer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    635\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m exc.UnspecializeRestartAnalysis:\n\u001b[32m    636\u001b[39m     speculation_log.clear()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Narwal\\fine_tuning_embedding_models\\.venv\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py:2796\u001b[39m, in \u001b[36mInstructionTranslator.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   2795\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m2796\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Narwal\\fine_tuning_embedding_models\\.venv\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py:983\u001b[39m, in \u001b[36mInstructionTranslatorBase.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    981\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    982\u001b[39m     \u001b[38;5;28mself\u001b[39m.output.push_tx(\u001b[38;5;28mself\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m983\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    984\u001b[39m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m    985\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m BackendCompilerFailed:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Narwal\\fine_tuning_embedding_models\\.venv\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py:895\u001b[39m, in \u001b[36mInstructionTranslatorBase.step\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    892\u001b[39m \u001b[38;5;28mself\u001b[39m.update_block_stack(inst)\n\u001b[32m    894\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m895\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdispatch_table\u001b[49m\u001b[43m[\u001b[49m\u001b[43minst\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopcode\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minst\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    896\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.output.should_exit\n\u001b[32m    897\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m exc.ObservedException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Narwal\\fine_tuning_embedding_models\\.venv\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py:2987\u001b[39m, in \u001b[36mInstructionTranslator.RETURN_VALUE\u001b[39m\u001b[34m(self, inst)\u001b[39m\n\u001b[32m   2986\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mRETURN_VALUE\u001b[39m(\u001b[38;5;28mself\u001b[39m, inst):\n\u001b[32m-> \u001b[39m\u001b[32m2987\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_return\u001b[49m\u001b[43m(\u001b[49m\u001b[43minst\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Narwal\\fine_tuning_embedding_models\\.venv\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py:2972\u001b[39m, in \u001b[36mInstructionTranslator._return\u001b[39m\u001b[34m(self, inst)\u001b[39m\n\u001b[32m   2967\u001b[39m _step_logger()(\n\u001b[32m   2968\u001b[39m     logging.INFO,\n\u001b[32m   2969\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mtorchdynamo done tracing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.f_code.co_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00minst.opname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   2970\u001b[39m )\n\u001b[32m   2971\u001b[39m log.debug(\u001b[33m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m triggered compile\u001b[39m\u001b[33m\"\u001b[39m, inst.opname)\n\u001b[32m-> \u001b[39m\u001b[32m2972\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompile_subgraph\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2973\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2974\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreason\u001b[49m\u001b[43m=\u001b[49m\u001b[43mGraphCompileReason\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2975\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreturn_value\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mframe_summary\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgraph_break\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[32m   2976\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2977\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2978\u001b[39m return_inst = (\n\u001b[32m   2979\u001b[39m     create_instruction(\u001b[33m\"\u001b[39m\u001b[33mRETURN_VALUE\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   2980\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m inst.opname == \u001b[33m\"\u001b[39m\u001b[33mRETURN_VALUE\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2981\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m create_instruction(\u001b[33m\"\u001b[39m\u001b[33mRETURN_CONST\u001b[39m\u001b[33m\"\u001b[39m, argval=inst.argval)\n\u001b[32m   2982\u001b[39m )\n\u001b[32m   2983\u001b[39m \u001b[38;5;28mself\u001b[39m.output.add_output_instructions([return_inst])\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Narwal\\fine_tuning_embedding_models\\.venv\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py:1117\u001b[39m, in \u001b[36mOutputGraph.compile_subgraph\u001b[39m\u001b[34m(self, tx, partial_convert, reason)\u001b[39m\n\u001b[32m   1114\u001b[39m append_prefix_insts()\n\u001b[32m   1115\u001b[39m \u001b[38;5;66;03m# optimization to generate better code in a common case\u001b[39;00m\n\u001b[32m   1116\u001b[39m \u001b[38;5;28mself\u001b[39m.add_output_instructions(\n\u001b[32m-> \u001b[39m\u001b[32m1117\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompile_and_call_fx_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mreversed\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mstack_values\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mroot\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1118\u001b[39m     + [create_instruction(\u001b[33m\"\u001b[39m\u001b[33mUNPACK_SEQUENCE\u001b[39m\u001b[33m\"\u001b[39m, arg=\u001b[38;5;28mlen\u001b[39m(stack_values))]\n\u001b[32m   1119\u001b[39m )\n\u001b[32m   1120\u001b[39m \u001b[38;5;66;03m# restore all the live local vars\u001b[39;00m\n\u001b[32m   1121\u001b[39m \u001b[38;5;28mself\u001b[39m.add_output_instructions(\n\u001b[32m   1122\u001b[39m     [PyCodegen(tx).create_store(var) \u001b[38;5;28;01mfor\u001b[39;00m var \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mreversed\u001b[39m(restore_vars)]\n\u001b[32m   1123\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Narwal\\fine_tuning_embedding_models\\.venv\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py:1369\u001b[39m, in \u001b[36mOutputGraph.compile_and_call_fx_graph\u001b[39m\u001b[34m(self, tx, rv, root)\u001b[39m\n\u001b[32m   1366\u001b[39m     \u001b[38;5;28mself\u001b[39m.tracing_context.fake_mode = backend_fake_mode\n\u001b[32m   1368\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.restore_global_state():\n\u001b[32m-> \u001b[39m\u001b[32m1369\u001b[39m     compiled_fn = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcall_user_compiler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1371\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfx\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_lazy_graph_module\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _LazyGraphModule\n\u001b[32m   1373\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(compiled_fn, _LazyGraphModule) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   1374\u001b[39m     \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mgetattr\u001b[39m(compiled_fn, \u001b[33m\"\u001b[39m\u001b[33m__self__\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m), _LazyGraphModule)\n\u001b[32m   1375\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m compiled_fn.\u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m_lazy_forward\u001b[39m\u001b[33m\"\u001b[39m  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1379\u001b[39m     \u001b[38;5;66;03m# this is a _LazyGraphModule. This makes it easier for dynamo to\u001b[39;00m\n\u001b[32m   1380\u001b[39m     \u001b[38;5;66;03m# optimize a _LazyGraphModule.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Narwal\\fine_tuning_embedding_models\\.venv\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py:1416\u001b[39m, in \u001b[36mOutputGraph.call_user_compiler\u001b[39m\u001b[34m(self, gm)\u001b[39m\n\u001b[32m   1412\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcall_user_compiler\u001b[39m(\u001b[38;5;28mself\u001b[39m, gm: fx.GraphModule) -> CompiledFn:\n\u001b[32m   1413\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m dynamo_timed(\n\u001b[32m   1414\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mOutputGraph.call_user_compiler\u001b[39m\u001b[33m\"\u001b[39m, phase_name=\u001b[33m\"\u001b[39m\u001b[33mbackend_compile\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1415\u001b[39m     ):\n\u001b[32m-> \u001b[39m\u001b[32m1416\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_user_compiler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgm\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Narwal\\fine_tuning_embedding_models\\.venv\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py:1465\u001b[39m, in \u001b[36mOutputGraph._call_user_compiler\u001b[39m\u001b[34m(self, gm)\u001b[39m\n\u001b[32m   1463\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m   1464\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m-> \u001b[39m\u001b[32m1465\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m BackendCompilerFailed(\u001b[38;5;28mself\u001b[39m.compiler_fn, e) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m   1467\u001b[39m signpost_event(\n\u001b[32m   1468\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mdynamo\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   1469\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mOutputGraph.call_user_compiler\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1475\u001b[39m     },\n\u001b[32m   1476\u001b[39m )\n\u001b[32m   1478\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m compiled_fn\n",
      "\u001b[31mBackendCompilerFailed\u001b[39m: backend='inductor' raised:\nRuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton\n\nSet TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n\n\nYou can suppress this exception and fall back to eager by setting:\n    import torch._dynamo\n    torch._dynamo.config.suppress_errors = True\n"
     ]
    }
   ],
   "source": [
    "sentences = [\n",
    "    'Which organization is Carmody Gaba Daman associated with?',\n",
    "    'Assistant General Counsel, U.S. General Services Administration, Washington, D.C.; Carmody Gaba Daman, Assistant General Counsel, U.S. General Services Administration, Washington, D.C.; Michael Blumenthal, Trial Attorney, U.S. Small Business Administration, Office of General Counsel, Washington, D.C. MEMORANDUM AND ORDER', # Corresponding Positive\n",
    "    'certain Solicitation requirements violate federal procurement statutes and agency regulations governing procurements involving small business offerors. See generally SHS MJAR at 14; VCH MJAR at 14. Having considered the parties’ arguments, applicable law, and the Administrative Record, this Court GRANTS in part and DENIES in part Plaintiffs’ Motions for Judgment on the', # Random Excerpt\n",
    "]\n",
    "\n",
    "embeddings = model.encode(sentences)\n",
    "print(embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98dfcaf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the similarity scores for the embeddings\n",
    "similarities = model.similarity(embeddings, embeddings)\n",
    "print(similarities[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7640e2b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fine-tuning-embedding-models",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
